{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-cORaO3Gz55"
   },
   "source": [
    "# AI허브 건강관리를 위한 음식 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 825,
     "status": "ok",
     "timestamp": 1653637432070,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "gO3CAQ_Nl7FY",
    "outputId": "8fb6816a-0bff-4a6c-c4bd-4011abb6a317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 27 07:43:51 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   49C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18139,
     "status": "ok",
     "timestamp": 1653637453836,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "hb5S7hOCiTVb",
    "outputId": "b92631fe-4de7-46f7-b762-5c74e8b4dd09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1653637471632,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "A2HTB2UGGz6A"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "root_dir = '/content/drive/MyDrive'\n",
    "base_dir = os.path.join(root_dir, 'data')\n",
    "split_dir = {split_name:os.path.join(base_dir,split_name)\n",
    "                for split_name in ['train','valid','test']}\n",
    "os.chdir(root_dir)\n",
    "random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 318810,
     "status": "ok",
     "timestamp": 1653638192227,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "NGcHgx1B8Gn2"
   },
   "outputs": [],
   "source": [
    "!unzip -qq data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lvQZ6pHGz6B"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3960,
     "status": "ok",
     "timestamp": 1653638255164,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "3uJLQBOAiRC9",
    "outputId": "1dd38db0-1d66-4d59-f221-32d3adb24e53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, AveragePooling2D, Input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import layers, regularizers, optimizers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1653638257448,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "x8_Yhnt0W3DJ",
    "outputId": "d3a2d620-991e-4f7b-8244-2bb29b3c2067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5543,
     "status": "ok",
     "timestamp": 1653638263988,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "z4O5O7IOGz6D",
    "outputId": "fe04342a-1c38-4702-bd89-f8f0e75efa52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81018 images belonging to 422 classes.\n",
      "Found 23521 images belonging to 422 classes.\n",
      "Found 11119 images belonging to 422 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale= 1./255) \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    split_dir['train'],\n",
    "    target_size = (299, 299),\n",
    "    batch_size = 32,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    split_dir['valid'],\n",
    "    target_size = (299, 299),\n",
    "    batch_size = 32,\n",
    "    shuffle=True,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    split_dir['test'],\n",
    "    target_size = (299, 299),\n",
    "    batch_size = 32,\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1653638294678,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "futMbdVXGz6F",
    "outputId": "6de9777f-7ca8-47d1-b6d4-972b7240aea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch data size: (32, 299, 299, 3)\n",
      "Batch label size: (32, 422)\n",
      "Generator length: 2532\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('Batch data size:', data_batch.shape)\n",
    "    print('Batch label size:', labels_batch.shape)\n",
    "    break\n",
    "print('Generator length:', len(train_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Checkpoint Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1653638298113,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "7rBRN2hNGz6F",
    "outputId": "6203d364-ad51-4d2f-8c0a-ae2b6180aefc"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "\n",
    "model_dir = os.path.join(root_dir, 'model')\n",
    "save_dir = os.path.join(model_dir, now)\n",
    "\n",
    "if not(os.path.isdir(model_dir)):\n",
    "    os.mkdir(model_dir)\n",
    "os.mkdir(save_dir)\n",
    "\n",
    "model_path = save_dir + '/{epoch:02d}-{val_accuracy:.4f}.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7074,
     "status": "ok",
     "timestamp": 1653638309843,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "hHP0mpUEiRD8",
    "outputId": "2c930340-04cc-4dac-ac93-bea888c88861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 0s 0us/step\n",
      "87924736/87910968 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=Input(shape=(299, 299, 3)))\n",
    "# base_model.trainable = False\n",
    "x = base_model.output\n",
    "x = AveragePooling2D(pool_size=(8, 8))(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(.2)(x)\n",
    "predictions = layers.Dense(422,kernel_initializer='glorot_uniform', \n",
    "                        kernel_regularizer=regularizers.l2(.0005), activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqHJaQlgpFrX"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras import models\n",
    "# model = models.load_model('./04-0.4752.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hphZD0F3pBp1"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_accuracy',\n",
    "                                verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5096396,
     "status": "ok",
     "timestamp": 1653650829723,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "jMbxSwGjiREC",
    "outputId": "0c9b107e-d77c-4723-abfa-1b632c458146",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 5.8183 - accuracy: 0.0126\n",
      "Epoch 1: val_accuracy improved from -inf to 0.02355, saving model to /content/drive/MyDrive/inception/model/220527_075818/01-0.0236.hdf5\n",
      "2532/2532 [==============================] - 2681s 1s/step - loss: 5.8183 - accuracy: 0.0126 - val_loss: 5.6666 - val_accuracy: 0.0236\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 4.8439 - accuracy: 0.0662\n",
      "Epoch 2: val_accuracy improved from 0.02355 to 0.05650, saving model to /content/drive/MyDrive/inception/model/220527_075818/02-0.0565.hdf5\n",
      "2532/2532 [==============================] - 2476s 978ms/step - loss: 4.8439 - accuracy: 0.0662 - val_loss: 5.5205 - val_accuracy: 0.0565\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 4.1458 - accuracy: 0.1524\n",
      "Epoch 3: val_accuracy improved from 0.05650 to 0.16279, saving model to /content/drive/MyDrive/inception/model/220527_075818/03-0.1628.hdf5\n",
      "2532/2532 [==============================] - 2450s 967ms/step - loss: 4.1458 - accuracy: 0.1524 - val_loss: 4.2405 - val_accuracy: 0.1628\n",
      "Epoch 4/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 3.6869 - accuracy: 0.2285\n",
      "Epoch 4: val_accuracy improved from 0.16279 to 0.23388, saving model to /content/drive/MyDrive/inception/model/220527_075818/04-0.2339.hdf5\n",
      "2532/2532 [==============================] - 2394s 945ms/step - loss: 3.6869 - accuracy: 0.2285 - val_loss: 3.7667 - val_accuracy: 0.2339\n",
      "Epoch 5/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 3.3154 - accuracy: 0.2976\n",
      "Epoch 5: val_accuracy improved from 0.23388 to 0.29327, saving model to /content/drive/MyDrive/inception/model/220527_075818/05-0.2933.hdf5\n",
      "2532/2532 [==============================] - 2428s 959ms/step - loss: 3.3154 - accuracy: 0.2976 - val_loss: 3.3760 - val_accuracy: 0.2933\n"
     ]
    }
   ],
   "source": [
    "# Start with learning rate 0.005\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMbxSwGjiREC",
    "outputId": "cc946eec-8e5d-4245-e12e-037510e648ac",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 2.8664 - accuracy: 0.3938\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41907, saving model to /content/drive/MyDrive/inception/model/220527_114534/01-0.4191.hdf5\n",
      "2532/2532 [==============================] - 2466s 965ms/step - loss: 2.8664 - accuracy: 0.3938 - val_loss: 2.7278 - val_accuracy: 0.4191\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 2.6297 - accuracy: 0.4370\n",
      "Epoch 2: val_accuracy improved from 0.41907 to 0.45270, saving model to /content/drive/MyDrive/inception/model/220527_114534/02-0.4527.hdf5\n",
      "2532/2532 [==============================] - 2470s 975ms/step - loss: 2.6297 - accuracy: 0.4370 - val_loss: 2.5538 - val_accuracy: 0.4527\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 2.4562 - accuracy: 0.4699\n",
      "Epoch 3: val_accuracy improved from 0.45270 to 0.47702, saving model to /content/drive/MyDrive/inception/model/220527_114534/03-0.4770.hdf5\n",
      "2532/2532 [==============================] - 2445s 965ms/step - loss: 2.4562 - accuracy: 0.4699 - val_loss: 2.4203 - val_accuracy: 0.4770\n",
      "Epoch 4/5\n",
      "1408/2532 [===============>..............] - ETA: 16:36 - loss: 2.2949 - accuracy: 0.5056"
     ]
    }
   ],
   "source": [
    "# After 5epoch, change learning rate to 0.0005\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMbxSwGjiREC",
    "outputId": "084013c1-35f5-4e86-e3df-c5e0c708725d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 2.3404 - accuracy: 0.5042\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51333, saving model to /content/drive/MyDrive/Final/inception/model/220528_043655/01-0.5133.hdf5\n",
      "2532/2532 [==============================] - 2473s 966ms/step - loss: 2.3404 - accuracy: 0.5042 - val_loss: 2.2561 - val_accuracy: 0.5133\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 2.1862 - accuracy: 0.5314\n",
      "Epoch 2: val_accuracy did not improve from 0.51333\n",
      "2532/2532 [==============================] - 2405s 950ms/step - loss: 2.1862 - accuracy: 0.5314 - val_loss: 2.4653 - val_accuracy: 0.4768\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 2.0805 - accuracy: 0.5525\n",
      "Epoch 3: val_accuracy improved from 0.51333 to 0.55512, saving model to /content/drive/MyDrive/Final/inception/model/220528_043655/03-0.5551.hdf5\n",
      "2532/2532 [==============================] - 2462s 972ms/step - loss: 2.0805 - accuracy: 0.5525 - val_loss: 2.0630 - val_accuracy: 0.5551\n",
      "Epoch 4/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.9696 - accuracy: 0.5740\n",
      "Epoch 4: val_accuracy improved from 0.55512 to 0.56987, saving model to /content/drive/MyDrive/Final/inception/model/220528_043655/04-0.5699.hdf5\n",
      "2532/2532 [==============================] - 2419s 955ms/step - loss: 1.9696 - accuracy: 0.5740 - val_loss: 2.0083 - val_accuracy: 0.5699\n",
      "Epoch 5/5\n",
      "1482/2532 [================>.............] - ETA: 15:09 - loss: 1.8713 - accuracy: 0.5947"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMbxSwGjiREC",
    "outputId": "1233eaf4-4959-4a9b-9b11-d7415a48dbc0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.9094 - accuracy: 0.5964\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55478, saving model to /content/drive/MyDrive/model/220528_092640/01-0.5548.hdf5\n",
      "2532/2532 [==============================] - 2470s 966ms/step - loss: 1.9094 - accuracy: 0.5964 - val_loss: 2.1284 - val_accuracy: 0.5548\n",
      "Epoch 2/10\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.8003 - accuracy: 0.6166\n",
      "Epoch 2: val_accuracy improved from 0.55478 to 0.59874, saving model to /content/drive/MyDrive/model/220528_092640/02-0.5987.hdf5\n",
      "2532/2532 [==============================] - 2407s 950ms/step - loss: 1.8003 - accuracy: 0.6166 - val_loss: 1.8941 - val_accuracy: 0.5987\n",
      "Epoch 3/10\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.7182 - accuracy: 0.6352\n",
      "Epoch 3: val_accuracy improved from 0.59874 to 0.61422, saving model to /content/drive/MyDrive/model/220528_092640/03-0.6142.hdf5\n",
      "2532/2532 [==============================] - 2404s 949ms/step - loss: 1.7182 - accuracy: 0.6352 - val_loss: 1.8321 - val_accuracy: 0.6142\n",
      "Epoch 4/10\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.6353 - accuracy: 0.6523\n",
      "Epoch 4: val_accuracy did not improve from 0.61422\n",
      "2532/2532 [==============================] - 2396s 946ms/step - loss: 1.6353 - accuracy: 0.6523 - val_loss: 1.9517 - val_accuracy: 0.5913\n",
      "Epoch 5/10\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.5895 - accuracy: 0.6622\n",
      "Epoch 5: val_accuracy did not improve from 0.61422\n",
      "2532/2532 [==============================] - 2380s 940ms/step - loss: 1.5895 - accuracy: 0.6622 - val_loss: 1.8986 - val_accuracy: 0.6087\n",
      "Epoch 6/10\n",
      "  46/2532 [..............................] - ETA: 36:37 - loss: 1.4619 - accuracy: 0.6875"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=10, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12081025,
     "status": "ok",
     "timestamp": 1653805908064,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "hOUPHiwpUgPI",
    "outputId": "12206143-3d7d-43c7-c1b0-64c6f80ff28e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.6675 - accuracy: 0.6506\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59190, saving model to /content/drive/MyDrive/inception/model/220529_031005/01-0.5919.hdf5\n",
      "2532/2532 [==============================] - 2480s 970ms/step - loss: 1.6675 - accuracy: 0.6506 - val_loss: 1.9530 - val_accuracy: 0.5919\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.5833 - accuracy: 0.6659\n",
      "Epoch 2: val_accuracy did not improve from 0.59190\n",
      "2532/2532 [==============================] - 2406s 950ms/step - loss: 1.5833 - accuracy: 0.6659 - val_loss: 2.1770 - val_accuracy: 0.5532\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.5073 - accuracy: 0.6829\n",
      "Epoch 3: val_accuracy improved from 0.59190 to 0.62969, saving model to /content/drive/MyDrive/inception/model/220529_031005/03-0.6297.hdf5\n",
      "2532/2532 [==============================] - 2374s 937ms/step - loss: 1.5073 - accuracy: 0.6829 - val_loss: 1.7598 - val_accuracy: 0.6297\n",
      "Epoch 4/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.4955 - accuracy: 0.6837\n",
      "Epoch 4: val_accuracy did not improve from 0.62969\n",
      "2532/2532 [==============================] - 2382s 940ms/step - loss: 1.4955 - accuracy: 0.6837 - val_loss: 1.9594 - val_accuracy: 0.5991\n",
      "Epoch 5/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.4202 - accuracy: 0.6998\n",
      "Epoch 5: val_accuracy improved from 0.62969 to 0.64389, saving model to /content/drive/MyDrive/inception/model/220529_031005/05-0.6439.hdf5\n",
      "2532/2532 [==============================] - 2398s 947ms/step - loss: 1.4202 - accuracy: 0.6998 - val_loss: 1.7687 - val_accuracy: 0.6439\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GeG9rT1JYj00",
    "outputId": "b8d9d81e-31c0-4a1c-e2ce-226313e8598c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.3692 - accuracy: 0.7203\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62200, saving model to /content/drive/MyDrive/Final/inception/model/220529_070421/01-0.6220.hdf5\n",
      "2532/2532 [==============================] - 2534s 992ms/step - loss: 1.3692 - accuracy: 0.7203 - val_loss: 1.9107 - val_accuracy: 0.6220\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.3035 - accuracy: 0.7320\n",
      "Epoch 2: val_accuracy improved from 0.62200 to 0.64372, saving model to /content/drive/MyDrive/Final/inception/model/220529_070421/02-0.6437.hdf5\n",
      "2532/2532 [==============================] - 2465s 973ms/step - loss: 1.3035 - accuracy: 0.7320 - val_loss: 1.7450 - val_accuracy: 0.6437\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.2527 - accuracy: 0.7410\n",
      "Epoch 3: val_accuracy did not improve from 0.64372\n",
      "2532/2532 [==============================] - 2470s 975ms/step - loss: 1.2527 - accuracy: 0.7410 - val_loss: 1.8237 - val_accuracy: 0.6331\n",
      "Epoch 4/5\n",
      "2504/2532 [============================>.] - ETA: 24s - loss: 1.2333 - accuracy: 0.7455"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMbxSwGjiREC",
    "outputId": "0a92a252-f445-47a1-d484-c0e4b4fbbeda",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.9665 - accuracy: 0.8224\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71251, saving model to /content/drive/MyDrive/model/220530_003956/01-0.7125.hdf5\n",
      "2532/2532 [==============================] - 2444s 956ms/step - loss: 0.9665 - accuracy: 0.8224 - val_loss: 1.4090 - val_accuracy: 0.7125\n",
      "Epoch 2/7\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.8647 - accuracy: 0.8459\n",
      "Epoch 2: val_accuracy improved from 0.71251 to 0.71319, saving model to /content/drive/MyDrive/model/220530_003956/02-0.7132.hdf5\n",
      "2532/2532 [==============================] - 2407s 951ms/step - loss: 0.8647 - accuracy: 0.8459 - val_loss: 1.4091 - val_accuracy: 0.7132\n",
      "Epoch 3/7\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.8632 - accuracy: 0.8384\n",
      "Epoch 3: val_accuracy improved from 0.71319 to 0.71625, saving model to /content/drive/MyDrive/model/220530_003956/03-0.7163.hdf5\n",
      "2532/2532 [==============================] - 2399s 947ms/step - loss: 0.8632 - accuracy: 0.8384 - val_loss: 1.3927 - val_accuracy: 0.7163\n",
      "Epoch 4/7\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.8469 - accuracy: 0.8389\n",
      "Epoch 4: val_accuracy improved from 0.71625 to 0.72165, saving model to /content/drive/MyDrive/model/220530_003956/04-0.7217.hdf5\n",
      "2532/2532 [==============================] - 2404s 949ms/step - loss: 0.8469 - accuracy: 0.8389 - val_loss: 1.3617 - val_accuracy: 0.7217\n",
      "Epoch 5/7\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.8225 - accuracy: 0.8436\n",
      "Epoch 5: val_accuracy improved from 0.72165 to 0.72301, saving model to /content/drive/MyDrive/model/220530_003956/05-0.7230.hdf5\n",
      "2532/2532 [==============================] - 2397s 947ms/step - loss: 0.8225 - accuracy: 0.8436 - val_loss: 1.3517 - val_accuracy: 0.7230\n",
      "Epoch 6/7\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.7974 - accuracy: 0.8490\n",
      "Epoch 6: val_accuracy did not improve from 0.72301\n",
      "2532/2532 [==============================] - 2362s 933ms/step - loss: 0.7974 - accuracy: 0.8490 - val_loss: 1.4027 - val_accuracy: 0.7133\n",
      "Epoch 7/7\n",
      " 222/2532 [=>............................] - ETA: 33:21 - loss: 0.7570 - accuracy: 0.8612"
     ]
    }
   ],
   "source": [
    "# After slow down, change learning rate to 0.0001\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=7, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11992994,
     "status": "ok",
     "timestamp": 1653899016946,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "hOUPHiwpUgPI",
    "outputId": "c8de4098-ec08-407a-b1ed-e1092efcd361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.7428 - accuracy: 0.8683\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71817, saving model to /content/drive/MyDrive/inception/model/220530_050333/01-0.7182.hdf5\n",
      "2532/2532 [==============================] - 2445s 956ms/step - loss: 0.7428 - accuracy: 0.8683 - val_loss: 1.3701 - val_accuracy: 0.7182\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.7046 - accuracy: 0.8758\n",
      "Epoch 2: val_accuracy improved from 0.71817 to 0.72501, saving model to /content/drive/MyDrive/inception/model/220530_050333/02-0.7250.hdf5\n",
      "2532/2532 [==============================] - 2372s 937ms/step - loss: 0.7046 - accuracy: 0.8758 - val_loss: 1.3516 - val_accuracy: 0.7250\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.7146 - accuracy: 0.8703\n",
      "Epoch 3: val_accuracy improved from 0.72501 to 0.72527, saving model to /content/drive/MyDrive/inception/model/220530_050333/03-0.7253.hdf5\n",
      "2532/2532 [==============================] - 2371s 936ms/step - loss: 0.7146 - accuracy: 0.8703 - val_loss: 1.3428 - val_accuracy: 0.7253\n",
      "Epoch 4/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.7091 - accuracy: 0.8696\n",
      "Epoch 4: val_accuracy did not improve from 0.72527\n",
      "2532/2532 [==============================] - 2366s 934ms/step - loss: 0.7091 - accuracy: 0.8696 - val_loss: 1.3604 - val_accuracy: 0.7215\n",
      "Epoch 5/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.8720\n",
      "Epoch 5: val_accuracy improved from 0.72527 to 0.72752, saving model to /content/drive/MyDrive/inception/model/220530_050333/05-0.7275.hdf5\n",
      "2532/2532 [==============================] - 2394s 945ms/step - loss: 0.6942 - accuracy: 0.8720 - val_loss: 1.3389 - val_accuracy: 0.7275\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O72I_aLg8sVL",
    "outputId": "13573591-27e7-40bd-ab16-a9bd85e30447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.8718\n",
      "Epoch 1: val_accuracy did not improve from 0.72752\n",
      "2532/2532 [==============================] - 2408s 951ms/step - loss: 0.6898 - accuracy: 0.8718 - val_loss: 1.3749 - val_accuracy: 0.7191\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.6689 - accuracy: 0.8766\n",
      "Epoch 2: val_accuracy improved from 0.72752 to 0.72948, saving model to /content/drive/MyDrive/inception/model/220530_050333/02-0.7295.hdf5\n",
      "2532/2532 [==============================] - 2341s 924ms/step - loss: 0.6689 - accuracy: 0.8766 - val_loss: 1.3278 - val_accuracy: 0.7295\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.6565 - accuracy: 0.8789\n",
      "Epoch 3: val_accuracy did not improve from 0.72948\n",
      "2532/2532 [==============================] - 2358s 931ms/step - loss: 0.6565 - accuracy: 0.8789 - val_loss: 1.3403 - val_accuracy: 0.7254\n",
      "Epoch 4/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.8840\n",
      "Epoch 4: val_accuracy did not improve from 0.72948\n",
      "2532/2532 [==============================] - 2421s 956ms/step - loss: 0.6360 - accuracy: 0.8840 - val_loss: 1.3390 - val_accuracy: 0.7247\n",
      "Epoch 5/5\n",
      " 641/2532 [======>.......................] - ETA: 27:34 - loss: 0.6152 - accuracy: 0.8935"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMbxSwGjiREC",
    "outputId": "16c0b6d4-8809-4836-9d0e-d8cb0789aeb0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.6040 - accuracy: 0.8981\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71829, saving model to /content/drive/MyDrive/Final/inception/model/220530_113047/01-0.7183.hdf5\n",
      "2532/2532 [==============================] - 2483s 971ms/step - loss: 0.6040 - accuracy: 0.8981 - val_loss: 1.3830 - val_accuracy: 0.7183\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.9024\n",
      "Epoch 2: val_accuracy improved from 0.71829 to 0.72374, saving model to /content/drive/MyDrive/Final/inception/model/220530_113047/02-0.7237.hdf5\n",
      "2532/2532 [==============================] - 2429s 959ms/step - loss: 0.5817 - accuracy: 0.9024 - val_loss: 1.3613 - val_accuracy: 0.7237\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 0.6296 - accuracy: 0.8849\n",
      "Epoch 3: val_accuracy improved from 0.72374 to 0.73254, saving model to /content/drive/MyDrive/Final/inception/model/220530_113047/03-0.7325.hdf5\n",
      "2532/2532 [==============================] - 2449s 967ms/step - loss: 0.6296 - accuracy: 0.8849 - val_loss: 1.3358 - val_accuracy: 0.7325\n",
      "Epoch 4/5\n",
      "1999/2532 [======================>.......] - ETA: 7:57 - loss: 0.6067 - accuracy: 0.8895"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1653650829745,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "SI1mQTuBBBXW",
    "outputId": "9d2fd56a-ce68-4c37-bb5c-e23c61883efa"
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dict()\n",
    "history['accuracy'] = [0.0126, 0.0662, 0.1524, 0.2285, 0.2976, 0.3938, 0.4370, 0.4699, 0.5042, 0.5314, 0.5525, 0.5740, 0.5964, 0.6166, 0.6352, 0.6506, 0.6659, 0.6829, 0.6837, 0.6998, 0.7203, 0.7320, 0.7410, 0.8224, 0.8459, 0.8384, 0.8389, 0.8436, 0.8683, 0.8758, 0.8703, 0.8696, 0.8720, 0.8718, 0.8766, 0.8981, 0.9024, 0.8849]\n",
    "history['val_accuracy'] = [0.0236, 0.0565, 0.1628, 0.2339, 0.2933, 0.4191, 0.4527, 0.4770, 0.5133, 0.4768, 0.5551, 0.5699, 0.5548, 0.5987, 0.6142, 0.5919, 0.5532, 0.6297, 0.5991, 0.6439, 0.6220, 0.6437, 0.6331, 0.7125, 0.7132, 0.7163, 0.7217, 0.7230, 0.7182, 0.7250, 0.7253, 0.7215, 0.7275, 0.7191, 0.7295, 0.7183, 0.7237, 0.7325]\n",
    "history['loss'] = [5.8183, 4.8439, 4.1458, 3.6869, 3.3154, 2.8664, 2.6297, 2.4562, 2.3404, 2.1862, 2.0805, 1.9696, 1.9094, 1.8003, 1.7182, 1.6675, 1.5833, 1.5073, 1.4955, 1.4202, 1.3692, 1.3035, 1.2527, 0.9665, 0.8647, 0.8632, 0.8469, 0.8225, 0.7428, 0.7046, 0.7146, 0.7091, 0.6942, 0.6898, 0.6689, 0.6040, 0.5817, 0.6296]\n",
    "history['val_loss'] = [5.6666, 5.5205, 4.2405, 3.7667, 3.3760, 2.7278, 2.5538, 2.4203, 2.2561, 2.4653, 2.0630, 2.0083, 2.1284, 1.8941, 1.8321, 1.9530, 2.1770, 1.7598, 1.9594, 1.7687, 1.9107, 1.7450, 1.8237, 1.4090, 1.4091, 1.3927, 1.3617, 1.3517, 1.3701, 1.3516, 1.3428, 1.3604, 1.3389, 1.3749, 1.3278, 1.3830, 1.3613, 1.3358]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>5.8183</td>\n",
       "      <td>5.6666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>4.8439</td>\n",
       "      <td>5.5205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>4.1458</td>\n",
       "      <td>4.2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.2339</td>\n",
       "      <td>3.6869</td>\n",
       "      <td>3.7667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2976</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>3.3154</td>\n",
       "      <td>3.3760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.4191</td>\n",
       "      <td>2.8664</td>\n",
       "      <td>2.7278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4370</td>\n",
       "      <td>0.4527</td>\n",
       "      <td>2.6297</td>\n",
       "      <td>2.5538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.4770</td>\n",
       "      <td>2.4562</td>\n",
       "      <td>2.4203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5042</td>\n",
       "      <td>0.5133</td>\n",
       "      <td>2.3404</td>\n",
       "      <td>2.2561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5314</td>\n",
       "      <td>0.4768</td>\n",
       "      <td>2.1862</td>\n",
       "      <td>2.4653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.5551</td>\n",
       "      <td>2.0805</td>\n",
       "      <td>2.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5740</td>\n",
       "      <td>0.5699</td>\n",
       "      <td>1.9696</td>\n",
       "      <td>2.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5964</td>\n",
       "      <td>0.5548</td>\n",
       "      <td>1.9094</td>\n",
       "      <td>2.1284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.6166</td>\n",
       "      <td>0.5987</td>\n",
       "      <td>1.8003</td>\n",
       "      <td>1.8941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.6352</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>1.7182</td>\n",
       "      <td>1.8321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.6506</td>\n",
       "      <td>0.5919</td>\n",
       "      <td>1.6675</td>\n",
       "      <td>1.9530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.6659</td>\n",
       "      <td>0.5532</td>\n",
       "      <td>1.5833</td>\n",
       "      <td>2.1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.6297</td>\n",
       "      <td>1.5073</td>\n",
       "      <td>1.7598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.6837</td>\n",
       "      <td>0.5991</td>\n",
       "      <td>1.4955</td>\n",
       "      <td>1.9594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.6998</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>1.4202</td>\n",
       "      <td>1.7687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.7203</td>\n",
       "      <td>0.6220</td>\n",
       "      <td>1.3692</td>\n",
       "      <td>1.9107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.6437</td>\n",
       "      <td>1.3035</td>\n",
       "      <td>1.7450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>1.2527</td>\n",
       "      <td>1.8237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.8224</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>1.4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.7132</td>\n",
       "      <td>0.8647</td>\n",
       "      <td>1.4091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.8384</td>\n",
       "      <td>0.7163</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>1.3927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.8389</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>1.3617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.8436</td>\n",
       "      <td>0.7230</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>1.3517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.8683</td>\n",
       "      <td>0.7182</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>1.3701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.8758</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.7046</td>\n",
       "      <td>1.3516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.7253</td>\n",
       "      <td>0.7146</td>\n",
       "      <td>1.3428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>0.7091</td>\n",
       "      <td>1.3604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.8720</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>1.3389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.8718</td>\n",
       "      <td>0.7191</td>\n",
       "      <td>0.6898</td>\n",
       "      <td>1.3749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.8766</td>\n",
       "      <td>0.7295</td>\n",
       "      <td>0.6689</td>\n",
       "      <td>1.3278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.8981</td>\n",
       "      <td>0.7183</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>1.3830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.9024</td>\n",
       "      <td>0.7237</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.3613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.8849</td>\n",
       "      <td>0.7325</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>1.3358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  val_accuracy    loss  val_loss\n",
       "0     0.0126        0.0236  5.8183    5.6666\n",
       "1     0.0662        0.0565  4.8439    5.5205\n",
       "2     0.1524        0.1628  4.1458    4.2405\n",
       "3     0.2285        0.2339  3.6869    3.7667\n",
       "4     0.2976        0.2933  3.3154    3.3760\n",
       "5     0.3938        0.4191  2.8664    2.7278\n",
       "6     0.4370        0.4527  2.6297    2.5538\n",
       "7     0.4699        0.4770  2.4562    2.4203\n",
       "8     0.5042        0.5133  2.3404    2.2561\n",
       "9     0.5314        0.4768  2.1862    2.4653\n",
       "10    0.5525        0.5551  2.0805    2.0630\n",
       "11    0.5740        0.5699  1.9696    2.0083\n",
       "12    0.5964        0.5548  1.9094    2.1284\n",
       "13    0.6166        0.5987  1.8003    1.8941\n",
       "14    0.6352        0.6142  1.7182    1.8321\n",
       "15    0.6506        0.5919  1.6675    1.9530\n",
       "16    0.6659        0.5532  1.5833    2.1770\n",
       "17    0.6829        0.6297  1.5073    1.7598\n",
       "18    0.6837        0.5991  1.4955    1.9594\n",
       "19    0.6998        0.6439  1.4202    1.7687\n",
       "20    0.7203        0.6220  1.3692    1.9107\n",
       "21    0.7320        0.6437  1.3035    1.7450\n",
       "22    0.7410        0.6331  1.2527    1.8237\n",
       "23    0.8224        0.7125  0.9665    1.4090\n",
       "24    0.8459        0.7132  0.8647    1.4091\n",
       "25    0.8384        0.7163  0.8632    1.3927\n",
       "26    0.8389        0.7217  0.8469    1.3617\n",
       "27    0.8436        0.7230  0.8225    1.3517\n",
       "28    0.8683        0.7182  0.7428    1.3701\n",
       "29    0.8758        0.7250  0.7046    1.3516\n",
       "30    0.8703        0.7253  0.7146    1.3428\n",
       "31    0.8696        0.7215  0.7091    1.3604\n",
       "32    0.8720        0.7275  0.6942    1.3389\n",
       "33    0.8718        0.7191  0.6898    1.3749\n",
       "34    0.8766        0.7295  0.6689    1.3278\n",
       "35    0.8981        0.7183  0.6040    1.3830\n",
       "36    0.9024        0.7237  0.5817    1.3613\n",
       "37    0.8849        0.7325  0.6296    1.3358"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1653650829746,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "n-V_yQHUiREG",
    "outputId": "c373de48-5325-40c4-9d11-2002fc895b3b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "acc = history['accuracy']\n",
    "val_acc = history['val_accuracy']\n",
    "\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation acc\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4216,
     "status": "ok",
     "timestamp": 1653650833948,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "YmxOHxxkiREI",
    "outputId": "70b45641-ebc1-45c0-9640-cadeef60c80e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_9 (AveragePo  (None, 1, 1, 2048)  0           ['mixed10[0][0]']                \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 1, 2048)   0           ['average_pooling2d_9[0][0]']    \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 2048)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 422)          864678      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,667,462\n",
      "Trainable params: 22,633,030\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1653650834241,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "kkzT3KQ5iREK"
   },
   "outputs": [],
   "source": [
    "model.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXC0ABYsGz6J"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model = models.load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 116846,
     "status": "ok",
     "timestamp": 1653650951361,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "rtNPkj7fGz6K",
    "outputId": "808f67da-7233-411a-b5ea-b43122a376d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23521 images belonging to 422 classes.\n",
      "736/736 [==============================] - 116s 157ms/step - loss: 3.3760 - accuracy: 0.2933\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    split_dir['valid'],\n",
    "    target_size = (299, 299),\n",
    "    batch_size = 32,\n",
    "    shuffle=True,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "val_prediction = model.evaluate(val_generator, steps=len(val_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1653651016117,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "sqriuO3_R8S8",
    "outputId": "afcef143-dade-4080-a5c8-9945399419da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(val_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1653650951409,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "_GJ362ScGz6K",
    "outputId": "372831d1-50bd-47f3-f12d-7619de541715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'가리비': 0, '가지': 1, '가지구이': 2, '가츠동': 3, '간장': 4, '갈비구이': 5, '갈비탕': 6, '감': 7, '감귤주스': 8, '감자구이': 9, '감자그라탕': 10, '감자볶음': 11, '감자샐러드': 12, '감자스프': 13, '감자칩': 14, '감자튀김': 15, '거봉포도': 16, '건자두': 17, '건포도': 18, '게맛살': 19, '게장': 20, '겨자소스': 21, '경단': 22, '계란말이': 23, '계란볶음밥': 24, '계란샌드위치': 25, '계란찜': 26, '계란후라이': 27, '고구마': 28, '고등어': 29, '고등어구이': 30, '고르곤졸라': 31, '고르곤졸라피자': 32, '고추': 33, '고추장': 34, '고추장아찌': 35, '고춧가루': 36, '골드키위': 37, '곶감': 38, '과일주스': 39, '과일채소샐러드': 40, '구아바': 41, '국수': 42, '국화차': 43, '군고구마': 44, '귤': 45, '그라탕': 46, '그린올리브': 47, '김': 48, '김마끼': 49, '김밥': 50, '김치국': 51, '김치볶음밥': 52, '김치찌개': 53, '까르보나라': 54, '까망베르치즈': 55, '껌': 56, '꿀': 57, '나시고랭': 58, '낫또': 59, '냉면': 60, '녹즙': 61, '누텔라': 62, '다시마': 63, '단감': 64, '단호박': 65, '닭가슴살': 66, '닭가슴살샐러드': 67, '닭갈비': 68, '닭강정': 69, '닭고기볶음': 70, '닭날개': 71, '닭훈제구이': 72, '당근': 73, '당근주스': 74, '당근케이크': 75, '대추': 76, '대파': 77, '데리야끼치킨': 78, '도넛': 79, '도리아': 80, '도리야끼': 81, '돼지갈비찜': 82, '돼지감자': 83, '돼지고기볶음': 84, '돼지고기스테이크': 85, '두부': 86, '두부튀김': 87, '두유': 88, '등심스테이크': 89, '딤섬': 90, '딸기': 91, '딸기아이스크림': 92, '땅콩버터': 93, '떡갈비': 94, '떡국': 95, '똠양꿍': 96, '라멘': 97, '라면': 98, '라자냐': 99, '랍스타': 100, '레모네이드': 101, '레몬': 102, '로메인상추': 103, '롤케이크': 104, '리조또': 105, '리코타치즈': 106, '마': 107, '마늘구이': 108, '마늘장아찌': 109, '마들렌': 110, '마르게리따피자': 111, '마른오징어': 112, '마시멜로우': 113, '마요네즈': 114, '마카로니샐러드': 115, '마카롱': 116, '마테차': 117, '막걸리': 118, '막대사탕': 119, '만두': 120, '만두국': 121, '망고': 122, '매실': 123, '맥주': 124, '머핀': 125, '메밀': 126, '메쉬드포테이토': 127, '멜론': 128, '모둠회': 129, '모짜렐라치즈': 130, '무우': 131, '문어': 132, '물미역': 133, '뮤즐리': 134, '미소장국': 135, '미역나물': 136, '미트볼': 137, '밀감': 138, '바게트빵': 139, '바나나': 140, '바나나우유': 141, '바나나칩': 142, '바닐라아이스크림': 143, '바베큐치킨': 144, '밤': 145, '밥': 146, '방울토마토': 147, '백도': 148, '백향과': 149, '버섯 장아찌': 150, '버터': 151, '버터쿠키': 152, '번데기': 153, '베이글': 154, '베이글샌드위치': 155, '베이컨구이': 156, '베이컨피자': 157, '보드카': 158, '보리빵': 159, '보쌈': 160, '보이차': 161, '복숭아': 162, '볶음면': 163, '볶음쌀국수': 164, '봉골레파스타': 165, '부대찌개': 166, '부침개': 167, '붉은 양배추 절임': 168, '붕어빵': 169, '브라우니': 170, '브라질너트': 171, '브로콜리': 172, '블랙커피': 173, '블루베리': 174, '비빔밥': 175, '비엔나소시지': 176, '빵': 177, '뻥튀기': 178, '사과': 179, '사과샐러드': 180, '사과주스': 181, '사과파이': 182, '사이다': 183, '사탕': 184, '산딸기': 185, '살구': 186, '살사소스': 187, '삶은고구마': 188, '삶은달걀': 189, '삼겹살': 190, '삼계탕': 191, '상추': 192, '상추샐러드': 193, '새싹샐러드': 194, '새우': 195, '새우매운탕': 196, '새우볶음밥': 197, '새우튀김': 198, '생강차': 199, '생과일주스': 200, '생맥주': 201, '생선구이': 202, '생선튀김': 203, '생크림케이크': 204, '석류': 205, '설탕': 206, '셀러리': 207, '소고기육포': 208, '소금': 209, '소시지': 210, '솜사탕': 211, '송편': 212, '쇠고기구이': 213, '수박': 214, '수프': 215, '숙주나물': 216, '순대국밥': 217, '쉐이크': 218, '슈크림': 219, '스크램블드에그': 220, '스테이크': 221, '스튜': 222, '스파게티': 223, '슬라이스치즈': 224, '시금치': 225, '시럽': 226, '시리얼': 227, '시리얼바': 228, '시저샐러드': 229, '아마씨': 230, '아보카도': 231, '아보카도샐러드': 232, '아스파라거스볶음밥': 233, '아오리사과': 234, '아이스라떼': 235, '아이스커피': 236, '아이스크림': 237, '아이스티': 238, '아포가토': 239, '안심스테이크': 240, '알로에주스': 241, '애호박': 242, '액상요구르트': 243, '앵두': 244, '야끼소바': 245, '야채볶음': 246, '양꼬치': 247, '양념치킨': 248, '양배추': 249, '양배추샐러드': 250, '양배추쌈': 251, '양배추절임': 252, '양상추샐러드': 253, '양주': 254, '양파': 255, '양파샐러드': 256, '양파튀김': 257, '어묵국': 258, '어묵탕': 259, '어육소시지': 260, '에그타르트': 261, '연어구이': 262, '연어샐러드': 263, '연어초밥': 264, '연어회': 265, '오디': 266, '오렌지': 267, '오렌지주스': 268, '오리구이': 269, '오므라이스': 270, '오믈렛': 271, '오미자': 272, '오이': 273, '오이샐러드': 274, '오이피클': 275, '오코노미야끼': 276, '오트밀': 277, '와사비': 278, '와인': 279, '와플': 280, '우동': 281, '우유': 282, '유과': 283, '유자': 284, '육포': 285, '인삼': 286, '자두': 287, '자몽': 288, '자몽주스': 289, '잡곡식빵': 290, '잣': 291, '장어구이': 292, '장어초밥': 293, '적양배추': 294, '전복': 295, '절임배추': 296, '젤리': 297, '조미김': 298, '족발': 299, '주먹밥': 300, '주스': 301, '짬뽕': 302, '쨈빵': 303, '쪽갈비구이': 304, '쭈꾸미볶음': 305, '찐빵': 306, '찜닭': 307, '참깨': 308, '참외': 309, '참치통조림': 310, '참치회': 311, '채소주스': 312, '채소죽': 313, '천도복숭아': 314, '청포도': 315, '체리': 316, '초밥': 317, '초코머핀': 318, '초코아이스크림': 319, '초코우유': 320, '초코케이크': 321, '초코쿠키': 322, '초콜릿': 323, '춘권': 324, '츄러스': 325, '치즈볼': 326, '치즈스틱': 327, '치즈피자': 328, '치커리': 329, '치킨너겟': 330, '치킨카레': 331, '칠리소스': 332, '카나페': 333, '카라멜': 334, '카레라이스': 335, '카레소스': 336, '카카오닙스': 337, '카페모카': 338, '카푸치노': 339, '카프레제샐러드': 340, '캐러멜마끼아또': 341, '캘리포니아롤': 342, '커스터드크림': 343, '커피': 344, '컵라면': 345, '케이크': 346, '케일': 347, '케첩': 348, '코코아': 349, '콜라비': 350, '콤비네이션피자': 351, '콩나물': 352, '콩샐러드': 353, '쿠키': 354, '퀘사디아': 355, '크래커': 356, '크랜베리': 357, '크레페': 358, '크로와상': 359, '크림치즈': 360, '크림파스타': 361, '키위': 362, '타코야키': 363, '탄산음료': 364, '토마토샐러드': 365, '토마토주스': 366, '토스트': 367, '통밀빵': 368, '티라미수': 369, '파니니': 370, '파인애플': 371, '파전': 372, '파파야': 373, '파프리카': 374, '팝콘': 375, '팥': 376, '팥죽': 377, '팬네파스타': 378, '페퍼로니피자': 379, '포도': 380, '폭립': 381, '표고버섯': 382, '푸딩': 383, '풋고추': 384, '프레즐': 385, '프렌치토스트': 386, '피망': 387, '피스타치오': 388, '피칸': 389, '하와이안피자': 390, '한라봉': 391, '할라피뇨': 392, '할라피뇨피클': 393, '함박스테이크': 394, '핫도그': 395, '핫소스': 396, '핫윙': 397, '핫초코': 398, '핫케이크': 399, '해물덮밥': 400, '해물볶음': 401, '해바라기씨': 402, '해시브라운': 403, '햄': 404, '햄볶음밥': 405, '햄샌드위치': 406, '햄치즈샌드위치': 407, '호두': 408, '호두파이': 409, '호박씨': 410, '홍차': 411, '화이트와인': 412, '후라이드치킨': 413, '후라이드치킨날개': 414, '후라이드치킨다리': 415, '후랑크소시지': 416, '후추': 417, '훈제연어': 418, '훈제오리': 419, '훈제오리샐러드': 420, '흰죽': 421}\n",
      "{'가리비': 0, '가지': 1, '가지구이': 2, '가츠동': 3, '간장': 4, '갈비구이': 5, '갈비탕': 6, '감': 7, '감귤주스': 8, '감자구이': 9, '감자그라탕': 10, '감자볶음': 11, '감자샐러드': 12, '감자스프': 13, '감자칩': 14, '감자튀김': 15, '거봉포도': 16, '건자두': 17, '건포도': 18, '게맛살': 19, '게장': 20, '겨자소스': 21, '경단': 22, '계란말이': 23, '계란볶음밥': 24, '계란샌드위치': 25, '계란찜': 26, '계란후라이': 27, '고구마': 28, '고등어': 29, '고등어구이': 30, '고르곤졸라': 31, '고르곤졸라피자': 32, '고추': 33, '고추장': 34, '고추장아찌': 35, '고춧가루': 36, '골드키위': 37, '곶감': 38, '과일주스': 39, '과일채소샐러드': 40, '구아바': 41, '국수': 42, '국화차': 43, '군고구마': 44, '귤': 45, '그라탕': 46, '그린올리브': 47, '김': 48, '김마끼': 49, '김밥': 50, '김치국': 51, '김치볶음밥': 52, '김치찌개': 53, '까르보나라': 54, '까망베르치즈': 55, '껌': 56, '꿀': 57, '나시고랭': 58, '낫또': 59, '냉면': 60, '녹즙': 61, '누텔라': 62, '다시마': 63, '단감': 64, '단호박': 65, '닭가슴살': 66, '닭가슴살샐러드': 67, '닭갈비': 68, '닭강정': 69, '닭고기볶음': 70, '닭날개': 71, '닭훈제구이': 72, '당근': 73, '당근주스': 74, '당근케이크': 75, '대추': 76, '대파': 77, '데리야끼치킨': 78, '도넛': 79, '도리아': 80, '도리야끼': 81, '돼지갈비찜': 82, '돼지감자': 83, '돼지고기볶음': 84, '돼지고기스테이크': 85, '두부': 86, '두부튀김': 87, '두유': 88, '등심스테이크': 89, '딤섬': 90, '딸기': 91, '딸기아이스크림': 92, '땅콩버터': 93, '떡갈비': 94, '떡국': 95, '똠양꿍': 96, '라멘': 97, '라면': 98, '라자냐': 99, '랍스타': 100, '레모네이드': 101, '레몬': 102, '로메인상추': 103, '롤케이크': 104, '리조또': 105, '리코타치즈': 106, '마': 107, '마늘구이': 108, '마늘장아찌': 109, '마들렌': 110, '마르게리따피자': 111, '마른오징어': 112, '마시멜로우': 113, '마요네즈': 114, '마카로니샐러드': 115, '마카롱': 116, '마테차': 117, '막걸리': 118, '막대사탕': 119, '만두': 120, '만두국': 121, '망고': 122, '매실': 123, '맥주': 124, '머핀': 125, '메밀': 126, '메쉬드포테이토': 127, '멜론': 128, '모둠회': 129, '모짜렐라치즈': 130, '무우': 131, '문어': 132, '물미역': 133, '뮤즐리': 134, '미소장국': 135, '미역나물': 136, '미트볼': 137, '밀감': 138, '바게트빵': 139, '바나나': 140, '바나나우유': 141, '바나나칩': 142, '바닐라아이스크림': 143, '바베큐치킨': 144, '밤': 145, '밥': 146, '방울토마토': 147, '백도': 148, '백향과': 149, '버섯 장아찌': 150, '버터': 151, '버터쿠키': 152, '번데기': 153, '베이글': 154, '베이글샌드위치': 155, '베이컨구이': 156, '베이컨피자': 157, '보드카': 158, '보리빵': 159, '보쌈': 160, '보이차': 161, '복숭아': 162, '볶음면': 163, '볶음쌀국수': 164, '봉골레파스타': 165, '부대찌개': 166, '부침개': 167, '붉은 양배추 절임': 168, '붕어빵': 169, '브라우니': 170, '브라질너트': 171, '브로콜리': 172, '블랙커피': 173, '블루베리': 174, '비빔밥': 175, '비엔나소시지': 176, '빵': 177, '뻥튀기': 178, '사과': 179, '사과샐러드': 180, '사과주스': 181, '사과파이': 182, '사이다': 183, '사탕': 184, '산딸기': 185, '살구': 186, '살사소스': 187, '삶은고구마': 188, '삶은달걀': 189, '삼겹살': 190, '삼계탕': 191, '상추': 192, '상추샐러드': 193, '새싹샐러드': 194, '새우': 195, '새우매운탕': 196, '새우볶음밥': 197, '새우튀김': 198, '생강차': 199, '생과일주스': 200, '생맥주': 201, '생선구이': 202, '생선튀김': 203, '생크림케이크': 204, '석류': 205, '설탕': 206, '셀러리': 207, '소고기육포': 208, '소금': 209, '소시지': 210, '솜사탕': 211, '송편': 212, '쇠고기구이': 213, '수박': 214, '수프': 215, '숙주나물': 216, '순대국밥': 217, '쉐이크': 218, '슈크림': 219, '스크램블드에그': 220, '스테이크': 221, '스튜': 222, '스파게티': 223, '슬라이스치즈': 224, '시금치': 225, '시럽': 226, '시리얼': 227, '시리얼바': 228, '시저샐러드': 229, '아마씨': 230, '아보카도': 231, '아보카도샐러드': 232, '아스파라거스볶음밥': 233, '아오리사과': 234, '아이스라떼': 235, '아이스커피': 236, '아이스크림': 237, '아이스티': 238, '아포가토': 239, '안심스테이크': 240, '알로에주스': 241, '애호박': 242, '액상요구르트': 243, '앵두': 244, '야끼소바': 245, '야채볶음': 246, '양꼬치': 247, '양념치킨': 248, '양배추': 249, '양배추샐러드': 250, '양배추쌈': 251, '양배추절임': 252, '양상추샐러드': 253, '양주': 254, '양파': 255, '양파샐러드': 256, '양파튀김': 257, '어묵국': 258, '어묵탕': 259, '어육소시지': 260, '에그타르트': 261, '연어구이': 262, '연어샐러드': 263, '연어초밥': 264, '연어회': 265, '오디': 266, '오렌지': 267, '오렌지주스': 268, '오리구이': 269, '오므라이스': 270, '오믈렛': 271, '오미자': 272, '오이': 273, '오이샐러드': 274, '오이피클': 275, '오코노미야끼': 276, '오트밀': 277, '와사비': 278, '와인': 279, '와플': 280, '우동': 281, '우유': 282, '유과': 283, '유자': 284, '육포': 285, '인삼': 286, '자두': 287, '자몽': 288, '자몽주스': 289, '잡곡식빵': 290, '잣': 291, '장어구이': 292, '장어초밥': 293, '적양배추': 294, '전복': 295, '절임배추': 296, '젤리': 297, '조미김': 298, '족발': 299, '주먹밥': 300, '주스': 301, '짬뽕': 302, '쨈빵': 303, '쪽갈비구이': 304, '쭈꾸미볶음': 305, '찐빵': 306, '찜닭': 307, '참깨': 308, '참외': 309, '참치통조림': 310, '참치회': 311, '채소주스': 312, '채소죽': 313, '천도복숭아': 314, '청포도': 315, '체리': 316, '초밥': 317, '초코머핀': 318, '초코아이스크림': 319, '초코우유': 320, '초코케이크': 321, '초코쿠키': 322, '초콜릿': 323, '춘권': 324, '츄러스': 325, '치즈볼': 326, '치즈스틱': 327, '치즈피자': 328, '치커리': 329, '치킨너겟': 330, '치킨카레': 331, '칠리소스': 332, '카나페': 333, '카라멜': 334, '카레라이스': 335, '카레소스': 336, '카카오닙스': 337, '카페모카': 338, '카푸치노': 339, '카프레제샐러드': 340, '캐러멜마끼아또': 341, '캘리포니아롤': 342, '커스터드크림': 343, '커피': 344, '컵라면': 345, '케이크': 346, '케일': 347, '케첩': 348, '코코아': 349, '콜라비': 350, '콤비네이션피자': 351, '콩나물': 352, '콩샐러드': 353, '쿠키': 354, '퀘사디아': 355, '크래커': 356, '크랜베리': 357, '크레페': 358, '크로와상': 359, '크림치즈': 360, '크림파스타': 361, '키위': 362, '타코야키': 363, '탄산음료': 364, '토마토샐러드': 365, '토마토주스': 366, '토스트': 367, '통밀빵': 368, '티라미수': 369, '파니니': 370, '파인애플': 371, '파전': 372, '파파야': 373, '파프리카': 374, '팝콘': 375, '팥': 376, '팥죽': 377, '팬네파스타': 378, '페퍼로니피자': 379, '포도': 380, '폭립': 381, '표고버섯': 382, '푸딩': 383, '풋고추': 384, '프레즐': 385, '프렌치토스트': 386, '피망': 387, '피스타치오': 388, '피칸': 389, '하와이안피자': 390, '한라봉': 391, '할라피뇨': 392, '할라피뇨피클': 393, '함박스테이크': 394, '핫도그': 395, '핫소스': 396, '핫윙': 397, '핫초코': 398, '핫케이크': 399, '해물덮밥': 400, '해물볶음': 401, '해바라기씨': 402, '해시브라운': 403, '햄': 404, '햄볶음밥': 405, '햄샌드위치': 406, '햄치즈샌드위치': 407, '호두': 408, '호두파이': 409, '호박씨': 410, '홍차': 411, '화이트와인': 412, '후라이드치킨': 413, '후라이드치킨날개': 414, '후라이드치킨다리': 415, '후랑크소시지': 416, '후추': 417, '훈제연어': 418, '훈제오리': 419, '훈제오리샐러드': 420, '흰죽': 421}\n"
     ]
    }
   ],
   "source": [
    "food_classes = val_generator.class_indices\n",
    "print(food_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1653629887079,
     "user": {
      "displayName": "김민엽",
      "userId": "03578768081358188494"
     },
     "user_tz": -540
    },
    "id": "m61CTJwvGz6K",
    "outputId": "77d1dbc3-60ae-49fa-8758-e876903bc252"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "food_classes = {v:k for k,v in food_classes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6c8b2079989812a11d6b05a84f3dab0146bce280e1d744bfd0e1eb18afe9e7a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-cORaO3Gz55"
   },
   "source": [
    "# AI허브 건강관리를 위한 음식 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 825,
     "status": "ok",
     "timestamp": 1653637432070,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "gO3CAQ_Nl7FY",
    "outputId": "8fb6816a-0bff-4a6c-c4bd-4011abb6a317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 27 07:43:51 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   49C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18139,
     "status": "ok",
     "timestamp": 1653637453836,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "hb5S7hOCiTVb",
    "outputId": "b92631fe-4de7-46f7-b762-5c74e8b4dd09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1653637471632,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "A2HTB2UGGz6A"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "root_dir = '/content/drive/MyDrive'\n",
    "base_dir = os.path.join(root_dir, 'data')\n",
    "split_dir = {split_name:os.path.join(base_dir,split_name)\n",
    "                for split_name in ['train','valid','test']}\n",
    "os.chdir(root_dir)\n",
    "random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 318810,
     "status": "ok",
     "timestamp": 1653638192227,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "NGcHgx1B8Gn2"
   },
   "outputs": [],
   "source": [
    "!unzip -qq data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lvQZ6pHGz6B"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3960,
     "status": "ok",
     "timestamp": 1653638255164,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "3uJLQBOAiRC9",
    "outputId": "1dd38db0-1d66-4d59-f221-32d3adb24e53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten, AveragePooling2D, Input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import layers, regularizers, optimizers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1653638257448,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "x8_Yhnt0W3DJ",
    "outputId": "d3a2d620-991e-4f7b-8244-2bb29b3c2067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5543,
     "status": "ok",
     "timestamp": 1653638263988,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "z4O5O7IOGz6D",
    "outputId": "fe04342a-1c38-4702-bd89-f8f0e75efa52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81018 images belonging to 422 classes.\n",
      "Found 23521 images belonging to 422 classes.\n",
      "Found 11119 images belonging to 422 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale= 1./255) \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    split_dir['train'],\n",
    "    target_size = (299, 299),\n",
    "    batch_size = 32,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    split_dir['valid'],\n",
    "    target_size = (299, 299),\n",
    "    batch_size = 32,\n",
    "    shuffle=True,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    split_dir['test'],\n",
    "    target_size = (299, 299),\n",
    "    batch_size = 32,\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1653638294678,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "futMbdVXGz6F",
    "outputId": "6de9777f-7ca8-47d1-b6d4-972b7240aea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch data size: (32, 299, 299, 3)\n",
      "Batch label size: (32, 422)\n",
      "Generator length: 2532\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('Batch data size:', data_batch.shape)\n",
    "    print('Batch label size:', labels_batch.shape)\n",
    "    break\n",
    "print('Generator length:', len(train_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Checkpoint Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1653638298113,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "7rBRN2hNGz6F",
    "outputId": "6203d364-ad51-4d2f-8c0a-ae2b6180aefc"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "\n",
    "model_dir = os.path.join(root_dir, 'model')\n",
    "save_dir = os.path.join(model_dir, now)\n",
    "\n",
    "if not(os.path.isdir(model_dir)):\n",
    "    os.mkdir(model_dir)\n",
    "os.mkdir(save_dir)\n",
    "\n",
    "model_path = save_dir + '/{epoch:02d}-{val_accuracy:.4f}.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7074,
     "status": "ok",
     "timestamp": 1653638309843,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "hHP0mpUEiRD8",
    "outputId": "2c930340-04cc-4dac-ac93-bea888c88861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 0s 0us/step\n",
      "87924736/87910968 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=Input(shape=(299, 299, 3)))\n",
    "# base_model.trainable = False\n",
    "x = base_model.output\n",
    "x = AveragePooling2D(pool_size=(8, 8))(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(.2)(x)\n",
    "predictions = layers.Dense(422,kernel_initializer='glorot_uniform', \n",
    "                        kernel_regularizer=regularizers.l2(.0005), activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqHJaQlgpFrX"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras import models\n",
    "# model = models.load_model('./04-0.4752.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hphZD0F3pBp1"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_accuracy',\n",
    "                                verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5096396,
     "status": "ok",
     "timestamp": 1653650829723,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "jMbxSwGjiREC",
    "outputId": "0c9b107e-d77c-4723-abfa-1b632c458146",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 5.8183 - accuracy: 0.0126\n",
      "Epoch 1: val_accuracy improved from -inf to 0.02355, saving model to /content/drive/MyDrive/inception/model/220527_075818/01-0.0236.hdf5\n",
      "2532/2532 [==============================] - 2681s 1s/step - loss: 5.8183 - accuracy: 0.0126 - val_loss: 5.6666 - val_accuracy: 0.0236\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 4.8439 - accuracy: 0.0662\n",
      "Epoch 2: val_accuracy improved from 0.02355 to 0.05650, saving model to /content/drive/MyDrive/inception/model/220527_075818/02-0.0565.hdf5\n",
      "2532/2532 [==============================] - 2476s 978ms/step - loss: 4.8439 - accuracy: 0.0662 - val_loss: 5.5205 - val_accuracy: 0.0565\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 4.1458 - accuracy: 0.1524\n",
      "Epoch 3: val_accuracy improved from 0.05650 to 0.16279, saving model to /content/drive/MyDrive/inception/model/220527_075818/03-0.1628.hdf5\n",
      "2532/2532 [==============================] - 2450s 967ms/step - loss: 4.1458 - accuracy: 0.1524 - val_loss: 4.2405 - val_accuracy: 0.1628\n",
      "Epoch 4/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 3.6869 - accuracy: 0.2285\n",
      "Epoch 4: val_accuracy improved from 0.16279 to 0.23388, saving model to /content/drive/MyDrive/inception/model/220527_075818/04-0.2339.hdf5\n",
      "2532/2532 [==============================] - 2394s 945ms/step - loss: 3.6869 - accuracy: 0.2285 - val_loss: 3.7667 - val_accuracy: 0.2339\n",
      "Epoch 5/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 3.3154 - accuracy: 0.2976\n",
      "Epoch 5: val_accuracy improved from 0.23388 to 0.29327, saving model to /content/drive/MyDrive/inception/model/220527_075818/05-0.2933.hdf5\n",
      "2532/2532 [==============================] - 2428s 959ms/step - loss: 3.3154 - accuracy: 0.2976 - val_loss: 3.3760 - val_accuracy: 0.2933\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMbxSwGjiREC",
    "outputId": "cc946eec-8e5d-4245-e12e-037510e648ac",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 2.8664 - accuracy: 0.3938\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41907, saving model to /content/drive/MyDrive/inception/model/220527_114534/01-0.4191.hdf5\n",
      "2532/2532 [==============================] - 2466s 965ms/step - loss: 2.8664 - accuracy: 0.3938 - val_loss: 2.7278 - val_accuracy: 0.4191\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 2.6297 - accuracy: 0.4370\n",
      "Epoch 2: val_accuracy improved from 0.41907 to 0.45270, saving model to /content/drive/MyDrive/inception/model/220527_114534/02-0.4527.hdf5\n",
      "2532/2532 [==============================] - 2470s 975ms/step - loss: 2.6297 - accuracy: 0.4370 - val_loss: 2.5538 - val_accuracy: 0.4527\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 2.4562 - accuracy: 0.4699\n",
      "Epoch 3: val_accuracy improved from 0.45270 to 0.47702, saving model to /content/drive/MyDrive/inception/model/220527_114534/03-0.4770.hdf5\n",
      "2532/2532 [==============================] - 2445s 965ms/step - loss: 2.4562 - accuracy: 0.4699 - val_loss: 2.4203 - val_accuracy: 0.4770\n",
      "Epoch 4/5\n",
      "1408/2532 [===============>..............] - ETA: 16:36 - loss: 2.2949 - accuracy: 0.5056"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMbxSwGjiREC",
    "outputId": "084013c1-35f5-4e86-e3df-c5e0c708725d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 2.3404 - accuracy: 0.5042\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51333, saving model to /content/drive/MyDrive/Final/inception/model/220528_043655/01-0.5133.hdf5\n",
      "2532/2532 [==============================] - 2473s 966ms/step - loss: 2.3404 - accuracy: 0.5042 - val_loss: 2.2561 - val_accuracy: 0.5133\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 2.1862 - accuracy: 0.5314\n",
      "Epoch 2: val_accuracy did not improve from 0.51333\n",
      "2532/2532 [==============================] - 2405s 950ms/step - loss: 2.1862 - accuracy: 0.5314 - val_loss: 2.4653 - val_accuracy: 0.4768\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 2.0805 - accuracy: 0.5525\n",
      "Epoch 3: val_accuracy improved from 0.51333 to 0.55512, saving model to /content/drive/MyDrive/Final/inception/model/220528_043655/03-0.5551.hdf5\n",
      "2532/2532 [==============================] - 2462s 972ms/step - loss: 2.0805 - accuracy: 0.5525 - val_loss: 2.0630 - val_accuracy: 0.5551\n",
      "Epoch 4/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.9696 - accuracy: 0.5740\n",
      "Epoch 4: val_accuracy improved from 0.55512 to 0.56987, saving model to /content/drive/MyDrive/Final/inception/model/220528_043655/04-0.5699.hdf5\n",
      "2532/2532 [==============================] - 2419s 955ms/step - loss: 1.9696 - accuracy: 0.5740 - val_loss: 2.0083 - val_accuracy: 0.5699\n",
      "Epoch 5/5\n",
      "1482/2532 [================>.............] - ETA: 15:09 - loss: 1.8713 - accuracy: 0.5947"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMbxSwGjiREC",
    "outputId": "1233eaf4-4959-4a9b-9b11-d7415a48dbc0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.9094 - accuracy: 0.5964\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55478, saving model to /content/drive/MyDrive/model/220528_092640/01-0.5548.hdf5\n",
      "2532/2532 [==============================] - 2470s 966ms/step - loss: 1.9094 - accuracy: 0.5964 - val_loss: 2.1284 - val_accuracy: 0.5548\n",
      "Epoch 2/10\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.8003 - accuracy: 0.6166\n",
      "Epoch 2: val_accuracy improved from 0.55478 to 0.59874, saving model to /content/drive/MyDrive/model/220528_092640/02-0.5987.hdf5\n",
      "2532/2532 [==============================] - 2407s 950ms/step - loss: 1.8003 - accuracy: 0.6166 - val_loss: 1.8941 - val_accuracy: 0.5987\n",
      "Epoch 3/10\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.7182 - accuracy: 0.6352\n",
      "Epoch 3: val_accuracy improved from 0.59874 to 0.61422, saving model to /content/drive/MyDrive/model/220528_092640/03-0.6142.hdf5\n",
      "2532/2532 [==============================] - 2404s 949ms/step - loss: 1.7182 - accuracy: 0.6352 - val_loss: 1.8321 - val_accuracy: 0.6142\n",
      "Epoch 4/10\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.6353 - accuracy: 0.6523\n",
      "Epoch 4: val_accuracy did not improve from 0.61422\n",
      "2532/2532 [==============================] - 2396s 946ms/step - loss: 1.6353 - accuracy: 0.6523 - val_loss: 1.9517 - val_accuracy: 0.5913\n",
      "Epoch 5/10\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.5895 - accuracy: 0.6622\n",
      "Epoch 5: val_accuracy did not improve from 0.61422\n",
      "2532/2532 [==============================] - 2380s 940ms/step - loss: 1.5895 - accuracy: 0.6622 - val_loss: 1.8986 - val_accuracy: 0.6087\n",
      "Epoch 6/10\n",
      "  46/2532 [..............................] - ETA: 36:37 - loss: 1.4619 - accuracy: 0.6875"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=10, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12081025,
     "status": "ok",
     "timestamp": 1653805908064,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "hOUPHiwpUgPI",
    "outputId": "12206143-3d7d-43c7-c1b0-64c6f80ff28e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.6675 - accuracy: 0.6506\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59190, saving model to /content/drive/MyDrive/inception/model/220529_031005/01-0.5919.hdf5\n",
      "2532/2532 [==============================] - 2480s 970ms/step - loss: 1.6675 - accuracy: 0.6506 - val_loss: 1.9530 - val_accuracy: 0.5919\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.5833 - accuracy: 0.6659\n",
      "Epoch 2: val_accuracy did not improve from 0.59190\n",
      "2532/2532 [==============================] - 2406s 950ms/step - loss: 1.5833 - accuracy: 0.6659 - val_loss: 2.1770 - val_accuracy: 0.5532\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.5073 - accuracy: 0.6829\n",
      "Epoch 3: val_accuracy improved from 0.59190 to 0.62969, saving model to /content/drive/MyDrive/inception/model/220529_031005/03-0.6297.hdf5\n",
      "2532/2532 [==============================] - 2374s 937ms/step - loss: 1.5073 - accuracy: 0.6829 - val_loss: 1.7598 - val_accuracy: 0.6297\n",
      "Epoch 4/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.4955 - accuracy: 0.6837\n",
      "Epoch 4: val_accuracy did not improve from 0.62969\n",
      "2532/2532 [==============================] - 2382s 940ms/step - loss: 1.4955 - accuracy: 0.6837 - val_loss: 1.9594 - val_accuracy: 0.5991\n",
      "Epoch 5/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.4202 - accuracy: 0.6998\n",
      "Epoch 5: val_accuracy improved from 0.62969 to 0.64389, saving model to /content/drive/MyDrive/inception/model/220529_031005/05-0.6439.hdf5\n",
      "2532/2532 [==============================] - 2398s 947ms/step - loss: 1.4202 - accuracy: 0.6998 - val_loss: 1.7687 - val_accuracy: 0.6439\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GeG9rT1JYj00",
    "outputId": "b8d9d81e-31c0-4a1c-e2ce-226313e8598c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.3692 - accuracy: 0.7203\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62200, saving model to /content/drive/MyDrive/Final/inception/model/220529_070421/01-0.6220.hdf5\n",
      "2532/2532 [==============================] - 2534s 992ms/step - loss: 1.3692 - accuracy: 0.7203 - val_loss: 1.9107 - val_accuracy: 0.6220\n",
      "Epoch 2/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.3035 - accuracy: 0.7320\n",
      "Epoch 2: val_accuracy improved from 0.62200 to 0.64372, saving model to /content/drive/MyDrive/Final/inception/model/220529_070421/02-0.6437.hdf5\n",
      "2532/2532 [==============================] - 2465s 973ms/step - loss: 1.3035 - accuracy: 0.7320 - val_loss: 1.7450 - val_accuracy: 0.6437\n",
      "Epoch 3/5\n",
      "2532/2532 [==============================] - ETA: 0s - loss: 1.2527 - accuracy: 0.7410\n",
      "Epoch 3: val_accuracy did not improve from 0.64372\n",
      "2532/2532 [==============================] - 2470s 975ms/step - loss: 1.2527 - accuracy: 0.7410 - val_loss: 1.8237 - val_accuracy: 0.6331\n",
      "Epoch 4/5\n",
      "2504/2532 [============================>.] - ETA: 24s - loss: 1.2333 - accuracy: 0.7455"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=5, steps_per_epoch= len(train_generator), \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps= len(val_generator),\n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=[cb_checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1653650829745,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "SI1mQTuBBBXW",
    "outputId": "9d2fd56a-ce68-4c37-bb5c-e23c61883efa"
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dict()\n",
    "history['accuracy'] = [0.0126, 0.0662, 0.1524, 0.2285, 0.2976, 0.3938, 0.4370, 0.4699, 0.5042, 0.5314, 0.5525, 0.5740, 0.5964, 0.6166, 0.6352, 0.6506, 0.6659, 0.6829, 0.6837, 0.6998, 0.7203, 0.7320, 0.7410]\n",
    "history['val_accuracy'] = [0.0236, 0.0565, 0.1628, 0.2339, 0.2933, 0.4191, 0.4527, 0.4770, 0.5133, 0.4768, 0.5551, 0.5699, 0.5548, 0.5987, 0.6142, 0.5919, 0.5532, 0.6297, 0.5991, 0.6439, 0.6220, 0.6437, 0.6331]\n",
    "history['loss'] = [5.8183, 4.8439, 4.1458, 3.6869, 3.3154, 2.8664, 2.6297, 2.4562, 2.3404, 2.1862, 2.0805, 1.9696, 1.9094, 1.8003, 1.7182, 1.6675, 1.5833, 1.5073, 1.4955, 1.4202, 1.3692, 1.3035, 1.2527]\n",
    "history['val_loss'] = [5.6666, 5.5205, 4.2405, 3.7667, 3.3760, 2.7278, 2.5538, 2.4203, 2.2561, 2.4653, 2.0630, 2.0083, 2.1284, 1.8941, 1.8321, 1.9530, 2.1770, 1.7598, 1.9594, 1.7687, 1.9107, 1.7450, 1.8237]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>5.8183</td>\n",
       "      <td>5.6666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>4.8439</td>\n",
       "      <td>5.5205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>4.1458</td>\n",
       "      <td>4.2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.2339</td>\n",
       "      <td>3.6869</td>\n",
       "      <td>3.7667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2976</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>3.3154</td>\n",
       "      <td>3.3760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.4191</td>\n",
       "      <td>2.8664</td>\n",
       "      <td>2.7278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4370</td>\n",
       "      <td>0.4527</td>\n",
       "      <td>2.6297</td>\n",
       "      <td>2.5538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.4770</td>\n",
       "      <td>2.4562</td>\n",
       "      <td>2.4203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5042</td>\n",
       "      <td>0.5133</td>\n",
       "      <td>2.3404</td>\n",
       "      <td>2.2561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5314</td>\n",
       "      <td>0.4768</td>\n",
       "      <td>2.1862</td>\n",
       "      <td>2.4653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.5551</td>\n",
       "      <td>2.0805</td>\n",
       "      <td>2.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5740</td>\n",
       "      <td>0.5699</td>\n",
       "      <td>1.9696</td>\n",
       "      <td>2.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5964</td>\n",
       "      <td>0.5548</td>\n",
       "      <td>1.9094</td>\n",
       "      <td>2.1284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.6166</td>\n",
       "      <td>0.5987</td>\n",
       "      <td>1.8003</td>\n",
       "      <td>1.8941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.6352</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>1.7182</td>\n",
       "      <td>1.8321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.6506</td>\n",
       "      <td>0.5919</td>\n",
       "      <td>1.6675</td>\n",
       "      <td>1.9530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.6659</td>\n",
       "      <td>0.5532</td>\n",
       "      <td>1.5833</td>\n",
       "      <td>2.1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.6297</td>\n",
       "      <td>1.5073</td>\n",
       "      <td>1.7598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.6837</td>\n",
       "      <td>0.5991</td>\n",
       "      <td>1.4955</td>\n",
       "      <td>1.9594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.6998</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>1.4202</td>\n",
       "      <td>1.7687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.7203</td>\n",
       "      <td>0.6220</td>\n",
       "      <td>1.3692</td>\n",
       "      <td>1.9107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.6437</td>\n",
       "      <td>1.3035</td>\n",
       "      <td>1.7450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>1.2527</td>\n",
       "      <td>1.8237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  val_accuracy    loss  val_loss\n",
       "0     0.0126        0.0236  5.8183    5.6666\n",
       "1     0.0662        0.0565  4.8439    5.5205\n",
       "2     0.1524        0.1628  4.1458    4.2405\n",
       "3     0.2285        0.2339  3.6869    3.7667\n",
       "4     0.2976        0.2933  3.3154    3.3760\n",
       "5     0.3938        0.4191  2.8664    2.7278\n",
       "6     0.4370        0.4527  2.6297    2.5538\n",
       "7     0.4699        0.4770  2.4562    2.4203\n",
       "8     0.5042        0.5133  2.3404    2.2561\n",
       "9     0.5314        0.4768  2.1862    2.4653\n",
       "10    0.5525        0.5551  2.0805    2.0630\n",
       "11    0.5740        0.5699  1.9696    2.0083\n",
       "12    0.5964        0.5548  1.9094    2.1284\n",
       "13    0.6166        0.5987  1.8003    1.8941\n",
       "14    0.6352        0.6142  1.7182    1.8321\n",
       "15    0.6506        0.5919  1.6675    1.9530\n",
       "16    0.6659        0.5532  1.5833    2.1770\n",
       "17    0.6829        0.6297  1.5073    1.7598\n",
       "18    0.6837        0.5991  1.4955    1.9594\n",
       "19    0.6998        0.6439  1.4202    1.7687\n",
       "20    0.7203        0.6220  1.3692    1.9107\n",
       "21    0.7320        0.6437  1.3035    1.7450\n",
       "22    0.7410        0.6331  1.2527    1.8237"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1653650829746,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "n-V_yQHUiREG",
    "outputId": "c373de48-5325-40c4-9d11-2002fc895b3b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3tklEQVR4nO3deZzNZfvA8c9l7PsyliyhsoYME4VKUdkiSqFkKUvy86Q8oUUqKkvl8bRIEVGJipA2PaSoGEvZyjoyZInshlmu3x/3GY4xyxlmnGWu9+t1XnPO93uf77nOd85cc5/7ey+iqhhjjAl+OfwdgDHGmMxhCd0YY0KEJXRjjAkRltCNMSZEWEI3xpgQYQndGGNChCX0ECYiX4pIt8wu608iEi0izbPguCoiV3nuTxCRZ3wpewGvc5+IfHOhcRqTFrF+6IFFRI55PcwPnAISPI/7qOoHlz6qwCEi0cBDqrowk4+rQBVV3ZJZZUWkErAdyKWq8ZkSqDFpyOnvAMy5VLVg0v20kpeI5LQkYQKFfR4DgzW5BAkRaSoiMSIyWET2AO+JSDERmS8i+0XkH8/98l7PWSwiD3nudxeRH0VkrKfsdhFpeYFlK4vIEhE5KiILReQNEZmeSty+xPiCiCz1HO8bEQn32t9VRHaIyAEReSqN83OdiOwRkTCvbe1F5DfP/QYi8pOIHBKRv0TkdRHJncqxpojICK/H//Y8Z7eI9ExWtrWIrBaRIyKyU0SGe+1e4vl5SESOicj1SefW6/mNRGSFiBz2/Gzk67nJ4HkuLiLved7DPyIyx2tfOxFZ43kPW0WkhWf7Oc1bIjI86fcsIpU8TU8PisifwP8822d5fg+HPZ+Rq72en09EXvH8Pg97PmP5ROQLEfm/ZO/nNxG5M6X3alJnCT24lAGKAxWB3rjf33uex5cDJ4HX03h+Q+APIBwYDUwSEbmAsh8Cy4ESwHCgaxqv6UuMXYAeQCkgNzAIQERqAm95jl/W83rlSYGq/gwcB25JdtwPPfcTgIGe93M90Azol0bceGJo4YnnVqAKkLz9/jjwAFAUaA087JWIbvT8LKqqBVX1p2THLg58AYz3vLdXgS9EpESy93DeuUlBeud5Gq4J72rPsV7zxNAAeB/4t+c93AhEp/IaKbkJqAHc7nn8Je48lQJWAd5NhGOB+kAj3Of4CSARmArcn1RIRK4BygELMhCHAVBVuwXoDfeH1dxzvylwGsibRvm6wD9ejxfjmmwAugNbvPblBxQok5GyuGQRD+T32j8dmO7je0opxqe9HvcDvvLcHwbM8NpXwHMOmqdy7BHAZM/9QrhkWzGVso8Cs70eK3CV5/4UYITn/mTgZa9yVb3LpnDcccBrnvuVPGVzeu3vDvzoud8VWJ7s+T8B3dM7Nxk5z8BluMRZLIVybyfFm9bnz/N4eNLv2eu9XZFGDEU9ZYrg/uGcBK5JoVwe4CDuugS4xP9mVvxNhfrNaujBZb+qxiY9EJH8IvK25yvsEdxX/KLezQ7J7Em6o6onPHcLZrBsWeCg1zaAnakF7GOMe7zun/CKqaz3sVX1OHAgtdfC1cY7iEgeoAOwSlV3eOKo6mmG2OOJ40VcbT0958QA7Ej2/hqKyCJPU8dhoK+Px0069o5k23bgaqdJUjs350jnPFfA/c7+SeGpFYCtPsabkjPnRkTCRORlT7PNEc7W9MM9t7wpvZaqngJmAveLSA6gM+4bhckgS+jBJXmXpMeBakBDVS3M2a/4qTWjZIa/gOIikt9rW4U0yl9MjH95H9vzmiVSK6yqG3AJsSXnNreAa7r5HVcLLAw8eSEx4L6hePsQmAtUUNUiwASv46bXhWw3ronE2+XALh/iSi6t87wT9zsrmsLzdgJXpnLM47hvZ0nKpFDG+z12AdrhmqWK4GrxSTH8DcSm8VpTgftwTWEnNFnzlPGNJfTgVgj3NfaQpz322ax+QU+NNwoYLiK5ReR64I4sivEToI2INPFcwHye9D+zHwIDcAltVrI4jgDHRKQ68LCPMcwEuotITc8/lOTxF8LVfmM97dFdvPbtxzV1XJHKsRcAVUWki4jkFJF7gZrAfB9jSx5HiudZVf/CtW2/6bl4mktEkhL+JKCHiDQTkRwiUs5zfgDWAJ085SOBu32I4RTuW1R+3LegpBgScc1Xr4pIWU9t/nrPtyk8CTwReAWrnV8wS+jBbRyQD1f7+Rn46hK97n24C4sHcO3WH+P+kFMyjguMUVXXA4/gkvRfwD9ATDpP+wh3veF/qvq31/ZBuGR7FHjHE7MvMXzpeQ//A7Z4fnrrBzwvIkdxbf4zvZ57AhgJLBXXu+a6ZMc+ALTB1a4P4C4StkkWt6/GkfZ57grE4b6l7MNdQ0BVl+Muur4GHAa+5+y3hmdwNep/gOc49xtPSt7HfUPaBWzwxOFtELAWWIFrMx/FuTnofaA27pqMuQA2sMhcNBH5GPhdVbP8G4IJXSLyANBbVZv4O5ZgZTV0k2Eicq2IXOn5it4C1246x89hmSDmac7qB0z0dyzBzBK6uRBlcF3qjuH6UD+sqqv9GpEJWiJyO+56w17Sb9YxabAmF2OMCRFWQzfGmBDht8m5wsPDtVKlSv56eWOMCUorV678W1VLprTPbwm9UqVKREVF+evljTEmKIlI8tHFZ1iTizHGhAhL6MYYEyIsoRtjTIgIqBWL4uLiiImJITY2Nv3Cxi/y5s1L+fLlyZUrl79DMcYkE1AJPSYmhkKFClGpUiVSX3fB+IuqcuDAAWJiYqhcubK/wzHGJBNQTS6xsbGUKFHCknmAEhFKlChh36CMCVABldABS+YBzn4/xgSugGpyMcaYkKQKf/4Ja9e627XXQvPky9NePEvoXg4cOECzZs0A2LNnD2FhYZQs6QZkLV++nNy5U1wkHoCoqCjef/99xo8fn+ZrNGrUiGXLlmVe0MaYwHLo0NnEnXRbtw4OHz5bZvBgS+hZrUSJEqxZswaA4cOHU7BgQQYNOrvIenx8PDlzpnzKIiMjiYyMTPc1LJkbEyJOn4bffz8/ee/0WoK2SBGoXRu6dIE6ddz9WrXc9ixgCT0d3bt3p3jx4qxevZp69epx77338uijj3Ly5Eny5cvHe++9R7Vq1Vi8eDFjx45l/vz5DB8+nD///JNt27bx559/8uijjzJgwAAAChYsyLFjx1i8eDHDhw8nPDycdevWUb9+faZPn46IsGDBAh577DHCw8OpV68e27ZtY/78c1cli46OpmvXrhw/fhyA119/nUaNGgEwevRopk2bRo4cOWjZsiUvv/wyW7ZsoW/fvuzfv5+wsDBmzZrFlVemtryjMeY8Bw/CsmWwdKm7rVgBSR0EcuWC6tXhhhtc0k5K3uXLwyW87hS4Cf3RR8FTW840devCuHEZftqmTZtYuHAhYWFhHDlyhCVLlpAzZ04WLlzIk08+yaeffnrec37//XcWLVrE0aNHqVatGg8//PB5fbdXr17N+vXrKVu2LI0bN2bp0qVERkbSp08flixZQuXKlencuXOKMZUqVYpvv/2WvHnzsnnzZjp37kxUVBRffvklc+bM4ZdffiF//vwcPHgQgPvuu48hQ4bQvn17YmNjSUxMzPB5MCbbUIXNm88m76VLXW0cIGdOiIiAvn1dW3idOlC1KqTRJHupBG5CDyAdO3YkLCwMgMOHD9OtWzc2b96MiBAXF5fic1q3bk2ePHnIkycPpUqVYu/evZQvX/6cMg0aNDizrW7dukRHR1OwYEGuuOKKM/28O3fuzMSJ5y/iEhcXR//+/VmzZg1hYWFs2rQJgIULF9KjRw/y53eLtRcvXpyjR4+ya9cu2rdvD7jBQcYYL7GxsHLl2eS9bBn87VnatVgxaNQIunaFxo1dEvf8fQWawE3oF1CTzioFChQ4c/+ZZ57h5ptvZvbs2URHR9O0adMUn5MnT54z98PCwoiPj/epjK8Ljrz22muULl2aX3/9lcTExDNJWlXP61poi5gYk4L4eFiwACZOhG+/dW3iAFWqQJs2Lok3buyaUnIEXA/vFAVHlAHk8OHDlCtXDoApU6Zk+vGrV6/Otm3biI6OBuDjj1NenP7w4cNcdtll5MiRg2nTppGQkADAbbfdxuTJkzlx4gQABw8epHDhwpQvX545c+YAcOrUqTP7jcl2YmJg+HCoXBnatYNVq6B/f5gzB/buhU2b4L33oFcvqFkzaJI5WELPsCeeeIKhQ4fSuHHjM0k0M+XLl48333yTFi1a0KRJE0qXLk2RFK6I9+vXj6lTp3LdddexadOmM98iWrRoQdu2bYmMjKRu3bqMHTsWgGnTpjF+/Hjq1KlDo0aN2LNnT6bHbkzASkiAL76Atm2hYkV4/nm4+mr47DPYsQNeecUl91Kl/B3pRfFpTVHPyu7/AcKAd1X15WT7/w3c53mYE6gBlFTVg6kdMzIyUpMvcLFx40Zq1KiRoTcQio4dO0bBggVRVR555BGqVKnCwIED/R3WGfZ7MkFj926YNAnefdcN7CldGnr2dLXvIJ2PSERWqmqKfaTTbUMXkTDgDeBWIAZYISJzVXVDUhlVHQOM8ZS/AxiYVjI3aXvnnXeYOnUqp0+fJiIigj59+vg7JGOCR2IifPMNvP02zJvnaufNm7taeNu2AdEbJav4clG0AbBFVbcBiMgMoB2wIZXynYGPMie87GngwIEBVSM3Jijs2AEffADvvAPR0VCyJDz+uKuNX3WVv6O7JHxJ6OUAr6FPxAANUyooIvmBFkD/VPb3BnoDXH755RkK1BhjzqEK69fD7Nnutnq1237zzfDyy3DnneDVkyw78CWhpzTMKbWG9zuApak1t6jqRGAiuDZ0nyI0xpgkiYnw88+uR8rs2bBli9t+/fUwejR06ADZeAS0Lwk9Bqjg9bg8sDuVsp2w5hZjTGY6fRoWLXIJ/PPPYc8eN9T+lltg0CDXLn7ZZf6OMiD4ktBXAFVEpDKwC5e0uyQvJCJFgJuA+zM1QmNM9nPsGHz5pauJf/GFm6mwQAFo2RLat4dWraBoUX9HGXDSTeiqGi8i/YGvcd0WJ6vqehHp69k/wVO0PfCNqh7PsmizWNOmTRk6dCi33377mW3jxo1j06ZNvPnmm6k+Z+zYsURGRtKqVSs+/PBDiib7oKU0c2Nyc+bMoWrVqtSsWROAYcOGceONN9I8C6bYNCbL7d3r+ngvWABHjrhRmRm5HT/ueqeEh8Ndd7kk3rw52LQVafJp6L+qLgAWJNs2IdnjKcCUzArMHzp37syMGTPOSegzZsxgzJgxPj1/wYIF6RdKxZw5c2jTps2ZhP78889f8LGM8YukJD5zJixZ4tq7q1aFcuXcxcmcOX2/FSjgEnjjxu6x8Y2q+uVWv359TW7Dhg3nbbuU/v77bw0PD9fY2FhVVd2+fbtWqFBBExMTtW/fvlq/fn2tWbOmDhs27MxzbrrpJl2xYoWqqlasWFH379+vqqojRozQqlWrarNmzbRTp046ZswYVVWdOHGiRkZGap06dbRDhw56/PhxXbp0qRYrVkwrVaqk11xzjW7ZskW7deums2bNUlXVhQsXat26dbVWrVrao0ePM/FVrFhRhw0bphEREVqrVi3duHHjee9p+/bt2qRJE42IiNCIiAhdunTpmX2jRo3SWrVqaZ06dXTw4MGqqrp582Zt1qyZ1qlTRyMiInTLli3nHdPfvycTQPbsUX3zTdWmTVVz5FAF1Ro1VIcNU123zt/RhSQgSlPJqwH7r88fs+eWKFGCBg0a8NVXX9GuXTtmzJjBvffei4gwcuRIihcvTkJCAs2aNeO3336jTp06KR5n5cqVzJgxg9WrVxMfH0+9evWoX78+AB06dKBXr14APP3000yaNIn/+7//o23btrRp04a77777nGPFxsbSvXt3vvvuO6pWrcoDDzzAW2+9xaOPPgpAeHg4q1at4s0332Ts2LG8++675zzfptk1mS6lmniNGvD003DPPW5IvfELm8slmaRmF3DNLUnzkc+cOZN69eoRERHB+vXr2bAhtXFV8MMPP9C+fXvy589P4cKFadu27Zl969at44YbbqB27dp88MEHrF+/Ps14/vjjDypXrkzVqlUB6NatG0uWLDmzv0OHDgDUr1//zIRe3uLi4ujVqxe1a9emY8eOZ+L2dZrd/AE6Tai5xPbuhbfecn28y5aFfv1cb5Onn3ar9KxfD889Z8nczwK2hu6v2XPvvPNOHnvsMVatWsXJkyepV68e27dvZ+zYsaxYsYJixYrRvXt3YpNWKklF8ilsk3Tv3p05c+ZwzTXXMGXKFBYvXpzmcTSduXaSpuBNbYpem2bXXBBVl6jnzXO35cvdturVXRLv2NEl70u4Go9Jn9XQkylYsCBNmzalZ8+eZ2rnR44coUCBAhQpUoS9e/fy5ZdfpnmMG2+8kdmzZ3Py5EmOHj3KvHnzzuw7evQol112GXFxcXzwwQdnthcqVIijR4+ed6zq1asTHR3NFs8AimnTpnHTTTf5/H5sml3js1On4Ouv3VSylSrBNde45J2Y6Grfa9fChg3ufq1alswDkCX0FHTu3Jlff/2VTp06AXDNNdcQERHB1VdfTc+ePWncuHGaz09ae7Ru3brcdddd3HDDDWf2vfDCCzRs2JBbb72V6tWrn9neqVMnxowZQ0REBFu3bj2zPW/evLz33nt07NiR2rVrkyNHDvr27evze7Fpdk2a9u1zc3936AAlSkCLFjB5srvg9M47brbC5cvhmWcsiQcBn6bPzQo2fW7wst9TEPNuSpk/H375xW0rVw7uuMPdbr4Z8uXzd6QmFRc1fa4xJsidOgXff3+2PXzHDrc9MtKt3HPHHa5GbrXvoGcJ3ZhQ9PffbpTm3LmuXfzYMVfrbt4cnnoKWrd2vVVCSGIiHDzoBpdeCqdPuy83gTShY8Al9JR6X5jAYT1hApQq/P67q4HPnQs//eQy3GWXQZcurhberFnINqUcO+a6wH/1lVvfecAA93azIpVs3QpvvOEuNZw4AXXqwLXXuluDBq5LflhY5r+uLwIqoefNm5cDBw5QokQJS+oBSFU5cODAma6Pxs/i4uDHH88m8aSL6XXrut4pd9wB9eoF1SLHF2LPHveF49dfoVs398Xk1ltdYh0wALp2dTMJXIykRZBef90dPywM7r7bLU+6YgV8+CFM8EyGUqCAO+1JCf7aa91qd5cipQXURdG4uDhiYmLS7eNt/Cdv3ryUL1+eXLly+TuU7CkhARYvhvffd0n80CG3pNott7hpZNu0gQoV0jtKyNi40U3A+PffbuBqq1buksHMmfCf/8DKlVCkCDz4IDzyCFxxRcaOf+QITJniauSbNrklSfv0cTfvFqvERNi82SX35cvdz9WrXSzgOhBFRp5N8A0bXvh61GldFA2ouVyMMalYt0518GDVcuXcfCmFC6t266b62WeqR4/6O7pUrVypeuJE1hx7yRLVYsVUS5dWjYo6f39iouqyZaqdOqnmzKkqotq2rerChW5fWjZuVH3kEdWCBd3pbthQdfp01VOnfI/v9Gn3/idMUH3wQdU6dc5Od/PYYxl7r95IYy4XS+jGBKo9e1Rfe001IsL9qYaFqbZurfrxx1mXJTPRzJku7CuuUJ0/P3OPPWOGau7cqtWqqW7bln75mBjVp59WLVnSxXT11S7RHjt2tkx8vOq8eaq33ebK5M6t2rWr6vLlmRf3sWOqP/zg/mFcKEvoxgSLEydUP/pItVUrl8BBtX591XHjVPfu9Xd0Ptu3TzU8XLVWLdXq1d3buOMO35JvWhITVceMccdr0kT1wIGMPf/kSdUpU87+jyxaVHXQINWxY90/HlAtW1b1hRcC93RbQjcmkCUkqC5apNqzp2qhQu7Psnx51SFDVNev93d0F6RjR1fDXbvWNVOMHq1aoIBq3ryqzz3nEmtGxcer9u/vTs8991zYMZIkJqr++KM7TtL/zSZN3Jef06cv/LiXgiV0YwLRjh1u3vCKFd2fYsGCqt27q/7vfy7JpyEuLnATT1JTy8iR527fudMl0Atphjl+XPXOO91zH3883dOTIbt2qf7+e+YdL6tZQjcmUJw+rTp7tmrLlu4qnYhrtP3gA5e10nDokGs77tLFNRUULqw6cODFN2NkpqSmlvr13T+dlCxceLYZpm3b9OPft89dlBRRHT8+82MONhed0IEWwB/AFmBIKmWaAmuA9cD36R3TErrJVrZuVR06VLVMGT3TUPvMM6rbt6f5tO3bXRJr3tz11ACXMLt3V+3c2W3LkUO1fXvV779Pv/dGVvNuakmLr80wmzerXnWVK/PZZ1kTc7C5qISOWxh6K3AFkBv4FaiZrExRYANwuedxqfSOawndhLxTp1z7Q/Pm7k8tRw53ZXDu3FSrrwkJqr/8ovrUU6q1a7unJa3qNniwa/eNjz9bPiZG9cknVYsXd+UiIlSnTlX1rFJ4SaXW1JIW72aYK69U/eKLs/t++sn98ypRwnU/NM7FJvTrga+9Hg8FhiYr0w8Ykd6xvG+W0E3I+uMP1X//+2wfucsvV33+eZe9UnD8uMvxvXqdrcCHhanedJPqK6+obtqU/kseP646caJqzZru+aVLu1rvpeqpsW+fe7tpNbWkJXkzzMSJqvnyuSTvy/vPTi42od8NvOv1uCvwerIy44A3gMXASuCB9I5rCd2ElNhY1w7etKn7s8qZU7VDB9Uvvzy3Su0lMVF11CiXuMB1cLnnHjeAJaPd8byP+fXXrok+qS91jx6qa9ZcxHvzga9NLWnxboYB1QYNArfroD9dbELvmEJC/2+yMq8DPwMFgHBgM1A1hWP1BqKAqMsvv/wSngJjssi+fa72nVS1vuIK1ZdeUv3rrzSfdvq0Gz0Iqu3aqX7zTcZGIfpi40bVhx9WzZ/fvc7NN6t+/nmq/18u2IU0taRl507V119P9xpxtnUpmlyGAMO9Hk8COqZ1XKuhm6C2dq3LyHnyuD+jli1Vv/rKp/50hw6dbVZ/+umsv5B54ID7JlC+/Nmab3R05hz7YptaTMZdbELPCWwDKntdFL06WZkawHeesvmBdUCttI5rCd0EnYQEd9UuKRvny6fat6/qhg0+HyI62rVz58ypOnlyFsaagtOn3QXTwoXdHCjz5l38MTt2VM2V6+KaWkzGpJXQ051XU1Xjgf7A18BGYKaqrheRviLS11NmI/AV8Buw3NNEsy69YxsTFI4fh7fegpo13TytGzfCSy/Bzp1uu4/L8a1Y4WbZ27XLrTnRo0cWx51MrlzwwAOwapVbA/qOO2DIEIiPv7DjzZrlbs8+65YbNQEgtUyf1TeroZuA9+efrq9gsWKuRh4Z6S58XsAQzc8+cxX6SpUyVKHPMidPqvbp497WDTe40ZIZYU0t/sPF1NCNyXZ++QU6d3arEowZ45a++fFHN9F1ly6uqusjVXj1VbjrLqhdG37+2ecKfZbKm9ctyDB9uqux160LCxf6/vz+/d1U7FOmQM6AWiYne7OEbgxAbKxbNKJBA05dd6NblubRR90qQLNmQePGGV5yJj7eJb7HH4cOHWDRIrdAQiC57z7XFFSyJNx2Gzz3nFtDIy2ffOIWkLCmlsBjCd1kb3/+SeLQp1hR5g6e67aVBmvfJZ/EUqPMQQYxlsXRlYiLy/hhjx51Cwi9+SYMGuQSYP78mR9+ZqhRw335uP9+GD7crQC0b1/KZffvh379oH59GDz4koZpfBBQS9AZc0mocmjeD3wzYjkLVpTkS1qwj9KIKNddBzfcIKxZ41Z6O33aLWHWooVb3a1Fi/RXlY+JcWXXrXNrUPbteyne1MVTdQsf9+8PxYvDjBlwww3nlrn3Xpg92y3tVru2f+LM7mwJOpPtJSaq/vbTMX253TK9Id8KDSNOQbV43uPapd0xnT5ddf/+c59z5Ii7mNmzpxtKnzQdS6NGqi++qPrbb+f3IV+1ys27VaiQGyQajNascRNihYW5/utJXetnzXLnYMQI/8aX3ZHGRVGroZuQdfw4fPcdLPjwEAu+SGTnseIA1M33B62bn6LVwGo0vDEPYWHpHysx0V08nD/f3VaudNsvv9zVxlu3dgsCd+0KxYrBF19AnTpZ+Oay2JEj8NBD7vLBHXfA2LHQpIl7vz//bBdC/SmtGroldBOS9v2VQESt0+w+mI+CHOVW+Y7WDf+mxZP1KNcmIsMXOJP76y933XT+fPj2W/fPAyAiwm3zXhE+WKm61e4fe8z9Q8uRw5paAoEldJN97N0LkybRaWQtZp+4nU9L9OG2AdXJ3bcnlCqVJS8ZGwvffw+bN0P37lCwYJa8jN8sX+5q6w8+CP/6l7+jMZbQTWhThaVLXZeSTz7h87iW3MnnvNB5A0+/X9XaB0xISSuhW7dFE7yOHnWjY665xnXHWLCAQw8+zsMlP+Waa2Dw1JqWzE22YgndBJ/1613funLl4OGHXdJ+913YtYtBcS+x72BOJk/O0IBOY0KCVV9McDh9GubMcc0q338PefK4TtH9+kGDBiDCwoUwaZIb8FKvnr8DNubSs4RuAtvRozBunEvke/a4+VVGj3ZTFXqN8Dl2DHr1gqpV3ZB0Y7IjS+gmMJ06BW+/DSNGuPHmrVq5Zpbbb3f955J5+mmIjoYffoB8+S59uMYEAkvoJrAkJMCHH8KwYS5D33ILvPwyXHttqk9ZtgzGj4dHHnGDX4zJruyiqAkMqm5ETkSEW4WheHH45hs3p2sayTw21vWPrlDBrTlhTHZmCd3439KlcOONboz5yZPw8cduTtdbb013ROeIEfD77zBxIhQqdIniNSZAWUI3l0RCArz2GjzxxNlh8qxd6+aYbdLEzTs+YQJs2AD33JNiO3lya9a41phu3VzTujHZnU8JXURaiMgfIrJFRIaksL+piBwWkTWe27DMD9UEq5gYaN7czQkyZgzUrxPH6jbPuAFBS5a4tpItW6BPH587j8fFQc+erqPLq69m8RswJkike1FURMKAN4BbgRhghYjMVdUNyYr+oKptsiBGE8Q++QR693bdyCf/5ygVv3+frp/dScNtz/BS04YMnNWIHOHFM3zcsWNh9Wr49FPX3G6M8a2G3gDYoqrbVPU0MANol7VhmWB39KirQXfsCFWqwJqXFtDjhSu4Zc4Afrt/DG1aJDBocRtadCnO7t0ZO/bvv7ul0u66yy3tZoxxfEno5YCdXo9jPNuSu15EfhWRL0Xk6kyJzgSl5ctdZ5UpU+CpgSf4seJ9XDWgNVSsCL/+Solp4/h0QT7eftutvVynDsyd69uxExPdzH/587vVgIwxZ/mS0FPqZpB8isZVQEVVvQb4LzAnxQOJ9BaRKBGJ2r9/f4YCNYEvIQFGjoRGjVwb9+IXfmDEB5XJNWeW647y009nVhUWcU0xq1a5RRPatXOj+E+cSPs13njDdYoZNw7KlMn692RMUEltKaOkG3A98LXX46HA0HSeEw2Ep1XGlqALLdHRqjfc4JYo69QhVv+5p7d7ULeu6q+/pvnc2FjVxx93xWvUcEugpWT7dtUCBVRbtDh/6TdjsgvSWILOlxr6CqCKiFQWkdxAJ+CcL8giUkbEdRgWkQa4mv+BTPmPYwLejBmuw8qaNfD+Y2v4cFllin422U2q8ssv6a7FliePu8j5zTdw6JCba+u111zzShJVV6MXcTMCXOSCQ8aEpHQTuqrGA/2Br4GNwExVXS8ifUUkaT3zu4F1IvIrMB7o5PlPYkLYkSNuUGfnzlCzajxrbh9M11cjkPASLpEPHw65c/t8vFtvhd9+gxYtXBfHVq3cfFzg2uO//RZGjXJNNMaY89mKReaC/PQT3Hcf7NgBz3TewtOLm5Pzr50wZIibhyVPngs+tqqrhQ8c6EZ/jh7t7teuDYsX+zTmyJiQZSsWmUwTHe0uXt5wA2hCIktaj2L4B1XIWTi/y/IjR15UMgfXnNK3r1uQuGxZN1NubKxbw8KSuTGps9kWjU82bnQDOj/80CXVXi1jeHlNC4rM3wD//jc8/zzkzZupr1mzpmu5GTUKqlVzc50bY1JnCd2kKSrKJfLZs9084wP6nOKxw89S/oNRbsTQjz+6fopZJE8e14JjjEmfJXRzHlU3xcqLL7qeJ0WLugUkBlT7mvDBD8Jff7lG7REj3AgfY0xAsBZJc4YqfPGFm/ywaVP49VfX3LEjaj/Pb+pE+P0toFgx11b+6quWzI0JMJbQDQkJbgryiAho0wZ27XIjMrdvU54o8z6FG1SHzz5z7eQrV7qO4saYgGMJPRuLj4dJk6BGDejUyS3jOXUqbN4M/VrvIF+Hlm6y8WrV3KihZ57JUL9yY8ylZW3o2dTata474MqVUK+em4b2zjshhya46vmTT7qC48e7fophYX6N1xiTPkvo2UxcnOu1MmKEu9j58cduilsR3GpBDz4IP//shmtOmOBmSDTGBAVrcslGVq926y0/+yzcfffZ1d4k7rRrH4+IgE2bYNo0WLDAkrkxQcYSejZw6pTrdnjttbB3L8yZ4wYIhYfjRu7Ur++yfIcObgTR/ffb7FfGBCFL6CFu+XKXr0eOdHl6wwY39ziqboHPRo3gn39g3jz46CMoVcrfIRtjLpAl9BB18iQ88QRcfz0cPuz6l0+Z4rqRc/q0W/bniSfcOm4bNrj+isaYoGYXRUPQsmWuB8umTdCrl6uIFyni2XnwoGtAX7TItcM895zNeGVMiLCEHkKOH4ennnI9DS+/3M0f3ry5V4HNm11NPDoa3n8funb1V6jGmCxgCT1EfP899OwJ27bBI4+4romFCiUr0KGDu9j53XdufL8xJqTYd+0QsG4d3HKLy9WLF8PrrydL5lOmuOWASpVyvVosmRsTkqyGHgLeegty5XLjgcLDvXYkJro2mJdfhmbN4JNP3GgiY0xIsoQe5I4dc+OA7r03WTI/ccK1kX/2mVtd+fXXXdY3xoQsn5pcRKSFiPwhIltEZEga5a4VkQQRuTvzQjRp+egjOHrULdl2xu7dcOONblWKV191Q/gtmRsT8tKtoYtIGPAGcCsQA6wQkbmquiGFcqOAr7MiUJOyt992iydfd51nw5o1cMcdbrDQ55+7+8aYbMGXGnoDYIuqblPV08AMoF0K5f4P+BTYl4nxmTRERbnZEvv29YzUnzfv7AXPH3+0ZG5MNuNLQi8H7PR6HOPZdoaIlAPaAxPSOpCI9BaRKBGJ2r9/f0ZjNclMmAAFCrgh/bz2mhvTX6OGG+9ft66/wzPGXGK+JPSUZmnSZI/HAYNVNSGtA6nqRFWNVNXIkiVL+hiiScnhw679vHNnKPzzN/DYY9C+vetvftll/g7PGOMHvvRyiQEqeD0uD+xOViYSmCFuhr5woJWIxKvqnMwI0pxv+nTXkaVv70ToOxQqVXIZ3lYUMibb8iWhrwCqiEhlYBfQCejiXUBVKyfdF5EpwHxL5llH1TW3REZC/e2fwKpVbii/JXNjsrV0E7qqxotIf1zvlTBgsqquF5G+nv1ptpubzLdsmRsd+u7b8W6CrVq1oEuX9J9ojAlpPg0sUtUFwIJk21JM5Kra/eLDMmmZMAEKF4ZOp6e5CbfmzrU1P40xNpdLsDlwAGbNgq6d4ynw0tNuwnOby9wYgw39DzpTp7ol5frkn+ZGhH70kS0XZ4wBrIYeVJIuhjZuGE/tKY9Dy5ZuiL8xxmAJPagsWuSazPuUnuOG9o8c6e+QjDEBxBJ6EHn7bSheLJG7v+0DnTpBRIS/QzLGBBBL6EFi7143E273iovJF3cEXnjB3yEZYwKMJfQgMXkyxMdD73UD4MEH4aqr/B2SMSbAWC+XIJCYCBMnws2lN1Dt8FYY9o2/QzLGBCCroQeBb76B6Gjou/c5+Ne/oGxZf4dkjAlAVkMPAhMmQKnch7gz7/9g8CZ/h2OMCVBWQw9wMTEwb57S8/Rb5B7yGBQr5u+QjDEBymroAe7ddxRNVHqFz4EB//N3OMaYAGYJPYDFx8O7b5zidhZxxXPd3PJExhiTCmtyCWBfzEtk14G89C09Bx56yN/hGGMCnNXQA9iE5/ZQjkRaj2lqi1cYY9JlNfQAtX1THF//WoaHSs0j5333+jscY0wQsIQeoN4ZsBZBeWh0VchhvyZjTPosUwSg04dOMOnbCrQpvozyD9zi73CMMUHCp4QuIi1E5A8R2SIiQ1LY305EfhORNSISJSJNMj/U7GPOI9+yL7EkfYcWt8UrjDE+S/eiqIiEAW8AtwIxwAoRmauqG7yKfQfMVVUVkTrATKB6VgQc8v75hwkzi1Ep3x5uG3i1v6MxxgQRX2roDYAtqrpNVU8DM4B23gVU9ZiqqudhAUAxF+SPwZNZFH8jvXuprftsjMkQXxJ6OWCn1+MYz7ZziEh7Efkd+ALomdKBRKS3p0kmav/+/RcSb2hbv56Jk3OSU+LpMfQyf0djjAkyviT0lBpxz6uBq+psVa0O3AmkuPqCqk5U1UhVjSxZsmSGAg15J04Q3X4gkxO70b5NHGXK+DsgY0yw8SWhxwAVvB6XB3anVlhVlwBXikj4RcaWrRzuN5TWm1+DAgV4YUw+f4djjAlCviT0FUAVEaksIrmBTsBc7wIicpWI644hIvWA3MCBzA42VMV9MJOOU1uzKUd1Pv08F9Wq+TsiY0wwSreXi6rGi0h/4GsgDJisqutFpK9n/wTgLuABEYkDTgL3el0kNWnQrdvo1+Mk33IPk9+O5xbrdm6MuUA+zeWiqguABcm2TfC6PwoYlbmhZQOnTzPmpvm8GzeAp/ofpsdDRfwdkTEmiNlIUT/65K6PGLxrAPc23snz/7Fkboy5OJbQ/eSXV5fSdf49NCqzlSkLK9h0LcaYi2ZpxA+if/qLtoOqUDb338xZXo68ef0dkTEmFFhCv8QO/R1P6+axxGlOFnweT8kKls2NMZnDEvolFBcHdzfYweYT5fhsaBTVWlT2d0jGmBBiCf0SUYWH79zNd9uv5J3GU2j64m3+DskYE2IsoV8io4YdY9KCsjxT4g26fdXF3+EYY0KQJfRLYNbHiQwdUZDOOT7muYVNoGBBf4dkjAlBtkh0FvvpJ+h6fyKNWcbkVw8hda/xd0jGmBBlCT0LbdsG7VrHUT5+B3PaTCLvgMn+DskYE8IsoWeRf/6B1i0TiD98nAVlexE+bbYtJ2eMyVKW0LNAYiLce6+ydbOyMEd7qn76EhQt6u+wjDEhzhJ6Fhg7Fr79VpjIw9z4Yku47jp/h2SMyQYsoWeyqCh46inl7hyzeajZnzDobX+HZIzJJiyhZ6Jjx6BLF+WyHPuYmP8x5L2l2KxbxphLxRJ6JvrXv2DLFlik91Dsneeh3HlraRtjTJaxhJ5JZs2CyZPhqbBR3NSyMHTt6u+QjDHZjCX0TPDnn9C7t9Kw4HqezfkqvL3GuigaYy45nxp4RaSFiPwhIltEZEgK++8Tkd88t2Uikm2GQyYkuMp4/Mk4PjjWjlz/fRXKlvV3WMaYbCjdGrqIhAFvALcCMcAKEZmrqhu8im0HblLVf0SkJTARaJgVAQeal1+GJUtgas6HubJdbbjvPn+HZIzJpnxpcmkAbFHVbQAiMgNoB5xJ6Kq6zKv8z0D5zAwyUP38Mzz7rNK5xLd0TZwDE9ZbU4sxxm98aXIpB+z0ehzj2ZaaB4EvU9ohIr1FJEpEovbv3+97lAHoyBFXGa9Q+DBvHeiIvPE6lCnj77CMMdmYLzX0lKqcmmJBkZtxCb1JSvtVdSKuOYbIyMgUjxEs+veH6GhlSVh7irRvBp06+TskY0w250tCjwEqeD0uD+xOXkhE6gDvAi1V9UDmhBeYPvwQpk2D4eXeoXHsWnjLmlqMMf7nS0JfAVQRkcrALqATcM6SOyJyOfAZ0FVVN2V6lAFk+3Z4+GFoXHEnT+3oBzM+gNKl/R2WMcakn9BVNV5E+gNfA2HAZFVdLyJ9PfsnAMOAEsCb4mqq8aoamXVh+0d8vKcTS2IC03c3I+fd7eGee/wdljHGAD4OLFLVBcCCZNsmeN1/CHgoc0MLPCNGuBWIPqw8jEpH/4E33rCmFmNMwLCRoj768Ud44QV4IOI3Oq9+EWbOhFKl/B2WMcacYVMB+uDQIbj/fqhU9hSvr23qmlk6dvR3WMYYcw6roadDFfr2hZgYZelVvSlUPJdrajHGmABjCT0d06fDxx/DyGaLaPjd+/DppxAe7u+wjDHmPNbkkoZTp2DoULiuznEGf98KOneGDh38HZYxxqTIauhpeP992LULJucZRFiJovDf//o7JGOMSZUl9FTEx8OoURBZdje3bpsAc+ZAiRL+DssYY1JlCT0VM2fC1q0wO+e/kHvvhXbt/B2SMcakyRJ6ChIT4cUX4epCO2ib8BW88ru/QzLGmHRZQk/B3Lmwfj1M50lyvPSULfZsjAkKltCTUYUXRyZyRa4Y7q24CgZO9ndIxhjjE0voySxcCCuicjCRF8g5/lXIk8ffIRljjE8soSczctgpysnfPNDqILRs6e9wjDHGZ5bQvSxdCt//nIfXwl4jz/gx/g7HGGMyxBK6l5GPHyScBHo9XhiuuMLf4RhjTIbY0H+P1Svi+fKX4gws8h4Fnh3k73CMMSbDLKF7vNgnmsIcpt9/qkH+/P4OxxhjMswSOrBx6UE+XX0F/SvNp+gDbf0djjHGXBCfErqItBCRP0Rki4gMSWF/dRH5SUROiUjQtVe83ON38nGSR6dF2pJyxpiglW5CF5Ew4A2gJVAT6CwiNZMVOwgMAMZmeoRZLHrub3ywuQG9I6Io2aSav8MxxpgL5ksNvQGwRVW3qeppYAZwzkxVqrpPVVcAcVkQY9ZJTGR0r83kIJHHp0f4OxpjjLkoviT0csBOr8cxnm0ZJiK9RSRKRKL2799/IYfIVH+Nn8Xkfa3pflM05WsW9nc4xhhzUXxJ6Ck1KuuFvJiqTlTVSFWNLFmy5IUcIvMcPswrTx4gjlwMfucq/8ZijDGZwJeEHgNU8HpcHtidNeFcOgcGj2bCyQfo3PIwV1axzj7GmODnSyZbAVQRkcoikhvoBMzN2rCy2Pr1jJ+Yl+MUZMjo4v6OxhhjMkW6Q/9VNV5E+gNfA2HAZFVdLyJ9PfsniEgZIAooDCSKyKNATVU9knWhXyBVjjw8mPFM585Wp6hVy2ZTNMaEBp/mclHVBcCCZNsmeN3fg2uKCXyffMJbP1zNIYry1HP+DsYYYzJP9pqc6/hxTg58kldz/sxtNyuRkTaIyBgTOrJXQn/pJSbtup19lODJp/wdjDHGZK7sk9C3buX06HGMzh9N4wi48UZ/B2SMMZkreyT0v/+Gtm2ZHvYAO0+E8/ZTNmWLMSb0hH5CP3wYbr+dhK3RvFxyBREloUULfwdljDGZL7RH1Bw/Dq1akfjbOkZ1WsXmmPw8+aTVzo0xoSl0a+ixsdCuHZt+OkCvGjEsmVqS1q2hQwd/B2aMMVkjNGvocXHE3d2Zl767ljo51/Pb7pJMngzz5kGO0HzHxhgTgjX0hARWth7GQ98OYw0R3NUWXn8dypTxd2DGGJO1QiqhnzyeyPDrv+GVtS9QslAsn02F9u39HZUxxlwaIdMAsXiRUqfcAUavbUmPiDVs/LOgJXNjTLYS9An90CHo3RtuvkVIPHyE7+56k3dW1qdoUX9HZowxl1ZQN7l8/jn06wd7/kpkEK/wXI8d5J/0X+uXaIzJloKyhr53L9xzD9x5J4TzN79oA8Z0WUP+d/5jydwYk20FXUL/6iuoUcPVzke0X0nU7suIbFcepkyBsDB/h2eMMX4TdE0uV14J9evDf1t9SfVBbeC25vDxx5Arl79DM8YYvwq6hF6lCnz7r/muP2KjRjB7NuSxVYeMMSbomlxYtAjuvhvq1oX58yF/fn9HZIwxAcGnhC4iLUTkDxHZIiJDUtgvIjLes/83EamX+aF6lC4NN93kGtOLFMmylzHGmGCTbpOLiIQBbwC3AjHAChGZq6obvIq1BKp4bg2Btzw/M1/NmvD111lyaGOMCWa+1NAbAFtUdZuqngZmAO2SlWkHvK/Oz0BREbksk2M1xhiTBl8Sejlgp9fjGM+2jJZBRHqLSJSIRO3fvz+jsRpjjEmDLwk9pZE6egFlUNWJqhqpqpElS5b0JT5jjDE+8iWhxwAVvB6XB3ZfQBljjDFZyJeEvgKoIiKVRSQ30AmYm6zMXOABT2+X64DDqvpXJsdqjDEmDen2clHVeBHpD3wNhAGTVXW9iPT17J8ALABaAVuAE0CPrAvZGGNMSnwaKaqqC3BJ23vbBK/7CjySuaEZY4zJiOAbKWqMMSZF4irXfnhhkf3ADiAc+NsvQQQuOyfns3NyPjsn58sO56SiqqbYTdBvCf1MACJRqhrp1yACjJ2T89k5OZ+dk/Nl93NiTS7GGBMiLKEbY0yICISEPtHfAQQgOyfns3NyPjsn58vW58TvbejGGGMyRyDU0I0xxmQCS+jGGBMi/JbQ01sFKTsSkWgRWSsia0Qkyt/x+IuITBaRfSKyzmtbcRH5VkQ2e34W82eMl1oq52S4iOzyfF7WiEgrf8Z4qYlIBRFZJCIbRWS9iPzLsz3bflb8ktC9VkFqCdQEOotITX/EEoBuVtW62bkvLTAFaJFs2xDgO1WtAnzneZydTOH8cwLwmufzUtczRUd2Eg88rqo1gOuARzx5JNt+VvxVQ/dlFSSTTanqEuBgss3tgKme+1OBOy9lTP6WyjnJ1lT1L1Vd5bl/FNiIW1gn235W/JXQfVrhKBtS4BsRWSkivf0dTIApnTQls+dnKT/HEyj6exZmn5ydmhaSE5FKQATwC9n4s+KvhO7TCkfZUGNVrYdrinpERG70d0AmoL0FXAnUBf4CXvFrNH4iIgWBT4FHVfWIv+PxJ38ldFvhKAWqutvzcx8wG9c0ZZy9SQuPe37u83M8fqeqe1U1QVUTgXfIhp8XEcmFS+YfqOpnns3Z9rPir4TuyypI2YqIFBCRQkn3gduAdWk/K1uZC3Tz3O8GfO7HWAJCUtLyaE82+7yIiACTgI2q+qrXrmz7WfHn9LmtgHGcXQVppF8CCRAicgWuVg5u4ZEPs+s5EZGPgKa4qVD3As8Cc4CZwOXAn0BHVc02FwlTOSdNcc0tCkQDfbLT0o8i0gT4AVgLJHo2P4lrR8+WnxUb+m+MMSHCRooaY0yIsIRujDEhwhK6McaECEvoxhgTIiyhG2NMiLCEbowxIcISujHGhIj/ByHURnvP4ah1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "acc = history['accuracy']\n",
    "val_acc = history['val_accuracy']\n",
    "\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation acc\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4216,
     "status": "ok",
     "timestamp": 1653650833948,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "YmxOHxxkiREI",
    "outputId": "70b45641-ebc1-45c0-9640-cadeef60c80e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_9 (AveragePo  (None, 1, 1, 2048)  0           ['mixed10[0][0]']                \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 1, 2048)   0           ['average_pooling2d_9[0][0]']    \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 2048)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 422)          864678      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,667,462\n",
      "Trainable params: 22,633,030\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1653650834241,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "kkzT3KQ5iREK"
   },
   "outputs": [],
   "source": [
    "model.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXC0ABYsGz6J"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model = models.load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 116846,
     "status": "ok",
     "timestamp": 1653650951361,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "rtNPkj7fGz6K",
    "outputId": "808f67da-7233-411a-b5ea-b43122a376d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23521 images belonging to 422 classes.\n",
      "736/736 [==============================] - 116s 157ms/step - loss: 3.3760 - accuracy: 0.2933\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    split_dir['valid'],\n",
    "    target_size = (299, 299),\n",
    "    batch_size = 32,\n",
    "    shuffle=True,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "val_prediction = model.evaluate(val_generator, steps=len(val_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1653651016117,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "sqriuO3_R8S8",
    "outputId": "afcef143-dade-4080-a5c8-9945399419da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(val_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1653650951409,
     "user": {
      "displayName": "김민엽",
      "userId": "11235644958609629845"
     },
     "user_tz": -540
    },
    "id": "_GJ362ScGz6K",
    "outputId": "372831d1-50bd-47f3-f12d-7619de541715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'가리비': 0, '가지': 1, '가지구이': 2, '가츠동': 3, '간장': 4, '갈비구이': 5, '갈비탕': 6, '감': 7, '감귤주스': 8, '감자구이': 9, '감자그라탕': 10, '감자볶음': 11, '감자샐러드': 12, '감자스프': 13, '감자칩': 14, '감자튀김': 15, '거봉포도': 16, '건자두': 17, '건포도': 18, '게맛살': 19, '게장': 20, '겨자소스': 21, '경단': 22, '계란말이': 23, '계란볶음밥': 24, '계란샌드위치': 25, '계란찜': 26, '계란후라이': 27, '고구마': 28, '고등어': 29, '고등어구이': 30, '고르곤졸라': 31, '고르곤졸라피자': 32, '고추': 33, '고추장': 34, '고추장아찌': 35, '고춧가루': 36, '골드키위': 37, '곶감': 38, '과일주스': 39, '과일채소샐러드': 40, '구아바': 41, '국수': 42, '국화차': 43, '군고구마': 44, '귤': 45, '그라탕': 46, '그린올리브': 47, '김': 48, '김마끼': 49, '김밥': 50, '김치국': 51, '김치볶음밥': 52, '김치찌개': 53, '까르보나라': 54, '까망베르치즈': 55, '껌': 56, '꿀': 57, '나시고랭': 58, '낫또': 59, '냉면': 60, '녹즙': 61, '누텔라': 62, '다시마': 63, '단감': 64, '단호박': 65, '닭가슴살': 66, '닭가슴살샐러드': 67, '닭갈비': 68, '닭강정': 69, '닭고기볶음': 70, '닭날개': 71, '닭훈제구이': 72, '당근': 73, '당근주스': 74, '당근케이크': 75, '대추': 76, '대파': 77, '데리야끼치킨': 78, '도넛': 79, '도리아': 80, '도리야끼': 81, '돼지갈비찜': 82, '돼지감자': 83, '돼지고기볶음': 84, '돼지고기스테이크': 85, '두부': 86, '두부튀김': 87, '두유': 88, '등심스테이크': 89, '딤섬': 90, '딸기': 91, '딸기아이스크림': 92, '땅콩버터': 93, '떡갈비': 94, '떡국': 95, '똠양꿍': 96, '라멘': 97, '라면': 98, '라자냐': 99, '랍스타': 100, '레모네이드': 101, '레몬': 102, '로메인상추': 103, '롤케이크': 104, '리조또': 105, '리코타치즈': 106, '마': 107, '마늘구이': 108, '마늘장아찌': 109, '마들렌': 110, '마르게리따피자': 111, '마른오징어': 112, '마시멜로우': 113, '마요네즈': 114, '마카로니샐러드': 115, '마카롱': 116, '마테차': 117, '막걸리': 118, '막대사탕': 119, '만두': 120, '만두국': 121, '망고': 122, '매실': 123, '맥주': 124, '머핀': 125, '메밀': 126, '메쉬드포테이토': 127, '멜론': 128, '모둠회': 129, '모짜렐라치즈': 130, '무우': 131, '문어': 132, '물미역': 133, '뮤즐리': 134, '미소장국': 135, '미역나물': 136, '미트볼': 137, '밀감': 138, '바게트빵': 139, '바나나': 140, '바나나우유': 141, '바나나칩': 142, '바닐라아이스크림': 143, '바베큐치킨': 144, '밤': 145, '밥': 146, '방울토마토': 147, '백도': 148, '백향과': 149, '버섯 장아찌': 150, '버터': 151, '버터쿠키': 152, '번데기': 153, '베이글': 154, '베이글샌드위치': 155, '베이컨구이': 156, '베이컨피자': 157, '보드카': 158, '보리빵': 159, '보쌈': 160, '보이차': 161, '복숭아': 162, '볶음면': 163, '볶음쌀국수': 164, '봉골레파스타': 165, '부대찌개': 166, '부침개': 167, '붉은 양배추 절임': 168, '붕어빵': 169, '브라우니': 170, '브라질너트': 171, '브로콜리': 172, '블랙커피': 173, '블루베리': 174, '비빔밥': 175, '비엔나소시지': 176, '빵': 177, '뻥튀기': 178, '사과': 179, '사과샐러드': 180, '사과주스': 181, '사과파이': 182, '사이다': 183, '사탕': 184, '산딸기': 185, '살구': 186, '살사소스': 187, '삶은고구마': 188, '삶은달걀': 189, '삼겹살': 190, '삼계탕': 191, '상추': 192, '상추샐러드': 193, '새싹샐러드': 194, '새우': 195, '새우매운탕': 196, '새우볶음밥': 197, '새우튀김': 198, '생강차': 199, '생과일주스': 200, '생맥주': 201, '생선구이': 202, '생선튀김': 203, '생크림케이크': 204, '석류': 205, '설탕': 206, '셀러리': 207, '소고기육포': 208, '소금': 209, '소시지': 210, '솜사탕': 211, '송편': 212, '쇠고기구이': 213, '수박': 214, '수프': 215, '숙주나물': 216, '순대국밥': 217, '쉐이크': 218, '슈크림': 219, '스크램블드에그': 220, '스테이크': 221, '스튜': 222, '스파게티': 223, '슬라이스치즈': 224, '시금치': 225, '시럽': 226, '시리얼': 227, '시리얼바': 228, '시저샐러드': 229, '아마씨': 230, '아보카도': 231, '아보카도샐러드': 232, '아스파라거스볶음밥': 233, '아오리사과': 234, '아이스라떼': 235, '아이스커피': 236, '아이스크림': 237, '아이스티': 238, '아포가토': 239, '안심스테이크': 240, '알로에주스': 241, '애호박': 242, '액상요구르트': 243, '앵두': 244, '야끼소바': 245, '야채볶음': 246, '양꼬치': 247, '양념치킨': 248, '양배추': 249, '양배추샐러드': 250, '양배추쌈': 251, '양배추절임': 252, '양상추샐러드': 253, '양주': 254, '양파': 255, '양파샐러드': 256, '양파튀김': 257, '어묵국': 258, '어묵탕': 259, '어육소시지': 260, '에그타르트': 261, '연어구이': 262, '연어샐러드': 263, '연어초밥': 264, '연어회': 265, '오디': 266, '오렌지': 267, '오렌지주스': 268, '오리구이': 269, '오므라이스': 270, '오믈렛': 271, '오미자': 272, '오이': 273, '오이샐러드': 274, '오이피클': 275, '오코노미야끼': 276, '오트밀': 277, '와사비': 278, '와인': 279, '와플': 280, '우동': 281, '우유': 282, '유과': 283, '유자': 284, '육포': 285, '인삼': 286, '자두': 287, '자몽': 288, '자몽주스': 289, '잡곡식빵': 290, '잣': 291, '장어구이': 292, '장어초밥': 293, '적양배추': 294, '전복': 295, '절임배추': 296, '젤리': 297, '조미김': 298, '족발': 299, '주먹밥': 300, '주스': 301, '짬뽕': 302, '쨈빵': 303, '쪽갈비구이': 304, '쭈꾸미볶음': 305, '찐빵': 306, '찜닭': 307, '참깨': 308, '참외': 309, '참치통조림': 310, '참치회': 311, '채소주스': 312, '채소죽': 313, '천도복숭아': 314, '청포도': 315, '체리': 316, '초밥': 317, '초코머핀': 318, '초코아이스크림': 319, '초코우유': 320, '초코케이크': 321, '초코쿠키': 322, '초콜릿': 323, '춘권': 324, '츄러스': 325, '치즈볼': 326, '치즈스틱': 327, '치즈피자': 328, '치커리': 329, '치킨너겟': 330, '치킨카레': 331, '칠리소스': 332, '카나페': 333, '카라멜': 334, '카레라이스': 335, '카레소스': 336, '카카오닙스': 337, '카페모카': 338, '카푸치노': 339, '카프레제샐러드': 340, '캐러멜마끼아또': 341, '캘리포니아롤': 342, '커스터드크림': 343, '커피': 344, '컵라면': 345, '케이크': 346, '케일': 347, '케첩': 348, '코코아': 349, '콜라비': 350, '콤비네이션피자': 351, '콩나물': 352, '콩샐러드': 353, '쿠키': 354, '퀘사디아': 355, '크래커': 356, '크랜베리': 357, '크레페': 358, '크로와상': 359, '크림치즈': 360, '크림파스타': 361, '키위': 362, '타코야키': 363, '탄산음료': 364, '토마토샐러드': 365, '토마토주스': 366, '토스트': 367, '통밀빵': 368, '티라미수': 369, '파니니': 370, '파인애플': 371, '파전': 372, '파파야': 373, '파프리카': 374, '팝콘': 375, '팥': 376, '팥죽': 377, '팬네파스타': 378, '페퍼로니피자': 379, '포도': 380, '폭립': 381, '표고버섯': 382, '푸딩': 383, '풋고추': 384, '프레즐': 385, '프렌치토스트': 386, '피망': 387, '피스타치오': 388, '피칸': 389, '하와이안피자': 390, '한라봉': 391, '할라피뇨': 392, '할라피뇨피클': 393, '함박스테이크': 394, '핫도그': 395, '핫소스': 396, '핫윙': 397, '핫초코': 398, '핫케이크': 399, '해물덮밥': 400, '해물볶음': 401, '해바라기씨': 402, '해시브라운': 403, '햄': 404, '햄볶음밥': 405, '햄샌드위치': 406, '햄치즈샌드위치': 407, '호두': 408, '호두파이': 409, '호박씨': 410, '홍차': 411, '화이트와인': 412, '후라이드치킨': 413, '후라이드치킨날개': 414, '후라이드치킨다리': 415, '후랑크소시지': 416, '후추': 417, '훈제연어': 418, '훈제오리': 419, '훈제오리샐러드': 420, '흰죽': 421}\n",
      "{'가리비': 0, '가지': 1, '가지구이': 2, '가츠동': 3, '간장': 4, '갈비구이': 5, '갈비탕': 6, '감': 7, '감귤주스': 8, '감자구이': 9, '감자그라탕': 10, '감자볶음': 11, '감자샐러드': 12, '감자스프': 13, '감자칩': 14, '감자튀김': 15, '거봉포도': 16, '건자두': 17, '건포도': 18, '게맛살': 19, '게장': 20, '겨자소스': 21, '경단': 22, '계란말이': 23, '계란볶음밥': 24, '계란샌드위치': 25, '계란찜': 26, '계란후라이': 27, '고구마': 28, '고등어': 29, '고등어구이': 30, '고르곤졸라': 31, '고르곤졸라피자': 32, '고추': 33, '고추장': 34, '고추장아찌': 35, '고춧가루': 36, '골드키위': 37, '곶감': 38, '과일주스': 39, '과일채소샐러드': 40, '구아바': 41, '국수': 42, '국화차': 43, '군고구마': 44, '귤': 45, '그라탕': 46, '그린올리브': 47, '김': 48, '김마끼': 49, '김밥': 50, '김치국': 51, '김치볶음밥': 52, '김치찌개': 53, '까르보나라': 54, '까망베르치즈': 55, '껌': 56, '꿀': 57, '나시고랭': 58, '낫또': 59, '냉면': 60, '녹즙': 61, '누텔라': 62, '다시마': 63, '단감': 64, '단호박': 65, '닭가슴살': 66, '닭가슴살샐러드': 67, '닭갈비': 68, '닭강정': 69, '닭고기볶음': 70, '닭날개': 71, '닭훈제구이': 72, '당근': 73, '당근주스': 74, '당근케이크': 75, '대추': 76, '대파': 77, '데리야끼치킨': 78, '도넛': 79, '도리아': 80, '도리야끼': 81, '돼지갈비찜': 82, '돼지감자': 83, '돼지고기볶음': 84, '돼지고기스테이크': 85, '두부': 86, '두부튀김': 87, '두유': 88, '등심스테이크': 89, '딤섬': 90, '딸기': 91, '딸기아이스크림': 92, '땅콩버터': 93, '떡갈비': 94, '떡국': 95, '똠양꿍': 96, '라멘': 97, '라면': 98, '라자냐': 99, '랍스타': 100, '레모네이드': 101, '레몬': 102, '로메인상추': 103, '롤케이크': 104, '리조또': 105, '리코타치즈': 106, '마': 107, '마늘구이': 108, '마늘장아찌': 109, '마들렌': 110, '마르게리따피자': 111, '마른오징어': 112, '마시멜로우': 113, '마요네즈': 114, '마카로니샐러드': 115, '마카롱': 116, '마테차': 117, '막걸리': 118, '막대사탕': 119, '만두': 120, '만두국': 121, '망고': 122, '매실': 123, '맥주': 124, '머핀': 125, '메밀': 126, '메쉬드포테이토': 127, '멜론': 128, '모둠회': 129, '모짜렐라치즈': 130, '무우': 131, '문어': 132, '물미역': 133, '뮤즐리': 134, '미소장국': 135, '미역나물': 136, '미트볼': 137, '밀감': 138, '바게트빵': 139, '바나나': 140, '바나나우유': 141, '바나나칩': 142, '바닐라아이스크림': 143, '바베큐치킨': 144, '밤': 145, '밥': 146, '방울토마토': 147, '백도': 148, '백향과': 149, '버섯 장아찌': 150, '버터': 151, '버터쿠키': 152, '번데기': 153, '베이글': 154, '베이글샌드위치': 155, '베이컨구이': 156, '베이컨피자': 157, '보드카': 158, '보리빵': 159, '보쌈': 160, '보이차': 161, '복숭아': 162, '볶음면': 163, '볶음쌀국수': 164, '봉골레파스타': 165, '부대찌개': 166, '부침개': 167, '붉은 양배추 절임': 168, '붕어빵': 169, '브라우니': 170, '브라질너트': 171, '브로콜리': 172, '블랙커피': 173, '블루베리': 174, '비빔밥': 175, '비엔나소시지': 176, '빵': 177, '뻥튀기': 178, '사과': 179, '사과샐러드': 180, '사과주스': 181, '사과파이': 182, '사이다': 183, '사탕': 184, '산딸기': 185, '살구': 186, '살사소스': 187, '삶은고구마': 188, '삶은달걀': 189, '삼겹살': 190, '삼계탕': 191, '상추': 192, '상추샐러드': 193, '새싹샐러드': 194, '새우': 195, '새우매운탕': 196, '새우볶음밥': 197, '새우튀김': 198, '생강차': 199, '생과일주스': 200, '생맥주': 201, '생선구이': 202, '생선튀김': 203, '생크림케이크': 204, '석류': 205, '설탕': 206, '셀러리': 207, '소고기육포': 208, '소금': 209, '소시지': 210, '솜사탕': 211, '송편': 212, '쇠고기구이': 213, '수박': 214, '수프': 215, '숙주나물': 216, '순대국밥': 217, '쉐이크': 218, '슈크림': 219, '스크램블드에그': 220, '스테이크': 221, '스튜': 222, '스파게티': 223, '슬라이스치즈': 224, '시금치': 225, '시럽': 226, '시리얼': 227, '시리얼바': 228, '시저샐러드': 229, '아마씨': 230, '아보카도': 231, '아보카도샐러드': 232, '아스파라거스볶음밥': 233, '아오리사과': 234, '아이스라떼': 235, '아이스커피': 236, '아이스크림': 237, '아이스티': 238, '아포가토': 239, '안심스테이크': 240, '알로에주스': 241, '애호박': 242, '액상요구르트': 243, '앵두': 244, '야끼소바': 245, '야채볶음': 246, '양꼬치': 247, '양념치킨': 248, '양배추': 249, '양배추샐러드': 250, '양배추쌈': 251, '양배추절임': 252, '양상추샐러드': 253, '양주': 254, '양파': 255, '양파샐러드': 256, '양파튀김': 257, '어묵국': 258, '어묵탕': 259, '어육소시지': 260, '에그타르트': 261, '연어구이': 262, '연어샐러드': 263, '연어초밥': 264, '연어회': 265, '오디': 266, '오렌지': 267, '오렌지주스': 268, '오리구이': 269, '오므라이스': 270, '오믈렛': 271, '오미자': 272, '오이': 273, '오이샐러드': 274, '오이피클': 275, '오코노미야끼': 276, '오트밀': 277, '와사비': 278, '와인': 279, '와플': 280, '우동': 281, '우유': 282, '유과': 283, '유자': 284, '육포': 285, '인삼': 286, '자두': 287, '자몽': 288, '자몽주스': 289, '잡곡식빵': 290, '잣': 291, '장어구이': 292, '장어초밥': 293, '적양배추': 294, '전복': 295, '절임배추': 296, '젤리': 297, '조미김': 298, '족발': 299, '주먹밥': 300, '주스': 301, '짬뽕': 302, '쨈빵': 303, '쪽갈비구이': 304, '쭈꾸미볶음': 305, '찐빵': 306, '찜닭': 307, '참깨': 308, '참외': 309, '참치통조림': 310, '참치회': 311, '채소주스': 312, '채소죽': 313, '천도복숭아': 314, '청포도': 315, '체리': 316, '초밥': 317, '초코머핀': 318, '초코아이스크림': 319, '초코우유': 320, '초코케이크': 321, '초코쿠키': 322, '초콜릿': 323, '춘권': 324, '츄러스': 325, '치즈볼': 326, '치즈스틱': 327, '치즈피자': 328, '치커리': 329, '치킨너겟': 330, '치킨카레': 331, '칠리소스': 332, '카나페': 333, '카라멜': 334, '카레라이스': 335, '카레소스': 336, '카카오닙스': 337, '카페모카': 338, '카푸치노': 339, '카프레제샐러드': 340, '캐러멜마끼아또': 341, '캘리포니아롤': 342, '커스터드크림': 343, '커피': 344, '컵라면': 345, '케이크': 346, '케일': 347, '케첩': 348, '코코아': 349, '콜라비': 350, '콤비네이션피자': 351, '콩나물': 352, '콩샐러드': 353, '쿠키': 354, '퀘사디아': 355, '크래커': 356, '크랜베리': 357, '크레페': 358, '크로와상': 359, '크림치즈': 360, '크림파스타': 361, '키위': 362, '타코야키': 363, '탄산음료': 364, '토마토샐러드': 365, '토마토주스': 366, '토스트': 367, '통밀빵': 368, '티라미수': 369, '파니니': 370, '파인애플': 371, '파전': 372, '파파야': 373, '파프리카': 374, '팝콘': 375, '팥': 376, '팥죽': 377, '팬네파스타': 378, '페퍼로니피자': 379, '포도': 380, '폭립': 381, '표고버섯': 382, '푸딩': 383, '풋고추': 384, '프레즐': 385, '프렌치토스트': 386, '피망': 387, '피스타치오': 388, '피칸': 389, '하와이안피자': 390, '한라봉': 391, '할라피뇨': 392, '할라피뇨피클': 393, '함박스테이크': 394, '핫도그': 395, '핫소스': 396, '핫윙': 397, '핫초코': 398, '핫케이크': 399, '해물덮밥': 400, '해물볶음': 401, '해바라기씨': 402, '해시브라운': 403, '햄': 404, '햄볶음밥': 405, '햄샌드위치': 406, '햄치즈샌드위치': 407, '호두': 408, '호두파이': 409, '호박씨': 410, '홍차': 411, '화이트와인': 412, '후라이드치킨': 413, '후라이드치킨날개': 414, '후라이드치킨다리': 415, '후랑크소시지': 416, '후추': 417, '훈제연어': 418, '훈제오리': 419, '훈제오리샐러드': 420, '흰죽': 421}\n"
     ]
    }
   ],
   "source": [
    "food_classes = val_generator.class_indices\n",
    "print(food_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1653629887079,
     "user": {
      "displayName": "김민엽",
      "userId": "03578768081358188494"
     },
     "user_tz": -540
    },
    "id": "m61CTJwvGz6K",
    "outputId": "77d1dbc3-60ae-49fa-8758-e876903bc252"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "food_classes = {v:k for k,v in food_classes.items()}\n",
    "\n",
    "food_image = np.expand_dims(food_image, axis=0)\n",
    "food_preds = model.predict(food_image)\n",
    "label_index = np.argmax(food_preds)\n",
    "label = food_classes[str(label_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6c8b2079989812a11d6b05a84f3dab0146bce280e1d744bfd0e1eb18afe9e7a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
